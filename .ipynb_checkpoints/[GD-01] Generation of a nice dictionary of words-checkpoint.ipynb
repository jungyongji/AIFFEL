{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7fc404fb",
   "metadata": {},
   "source": [
    "## Application of SentencePiece to the sentiment analysis of Naver moive review"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53485c82",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "fb64a637",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import konlpy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import sentencepiece as spm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from konlpy.tag import Mecab\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.initializers import Constant\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3943a7aa",
   "metadata": {},
   "source": [
    "## Data load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "781f5e56",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8112052</td>\n",
       "      <td>어릴때보고 지금다시봐도 재밌어요ㅋㅋ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8132799</td>\n",
       "      <td>디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4655635</td>\n",
       "      <td>폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9251303</td>\n",
       "      <td>와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>10067386</td>\n",
       "      <td>안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   8112052                                어릴때보고 지금다시봐도 재밌어요ㅋㅋ      1\n",
       "1   8132799  디자인을 배우는 학생으로, 외국디자이너와 그들이 일군 전통을 통해 발전해가는 문화산...      1\n",
       "2   4655635               폴리스스토리 시리즈는 1부터 뉴까지 버릴께 하나도 없음.. 최고.      1\n",
       "3   9251303  와.. 연기가 진짜 개쩔구나.. 지루할거라고 생각했는데 몰입해서 봤다.. 그래 이런...      1\n",
       "4  10067386                        안개 자욱한 밤하늘에 떠 있는 초승달 같은 영화.      1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_table(os.getenv('HOME') + '/aiffel/sp_tokenizer/data/nsmc/ratings.txt')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8331224b",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cf3702e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data의 크기 : 200000\n"
     ]
    }
   ],
   "source": [
    "print(f'Data의 크기 : {len(data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "17cef0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>125229</th>\n",
       "      <td>143967</td>\n",
       "      <td>이미 참여하셨습니다.qenansfyd123</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            id                 document  label\n",
       "125229  143967  이미 참여하셨습니다.qenansfyd123      0"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.document.str.contains('nan', na = False)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e65af51f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>3946738</td>\n",
       "      <td>굿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>740</th>\n",
       "      <td>4217807</td>\n",
       "      <td>재밌다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1369</th>\n",
       "      <td>3044092</td>\n",
       "      <td>재밋다</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1535</th>\n",
       "      <td>6924850</td>\n",
       "      <td>굿</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1896</th>\n",
       "      <td>2417941</td>\n",
       "      <td>쵝오</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199932</th>\n",
       "      <td>2334732</td>\n",
       "      <td>지루함...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199939</th>\n",
       "      <td>2105796</td>\n",
       "      <td>bad</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199944</th>\n",
       "      <td>2100743</td>\n",
       "      <td>재미없다...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199946</th>\n",
       "      <td>735755</td>\n",
       "      <td>에혀</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199966</th>\n",
       "      <td>7405830</td>\n",
       "      <td>재미 더럽게없다..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5456 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             id    document  label\n",
       "187     3946738           굿      1\n",
       "740     4217807         재밌다      1\n",
       "1369    3044092         재밋다      1\n",
       "1535    6924850           굿      1\n",
       "1896    2417941          쵝오      1\n",
       "...         ...         ...    ...\n",
       "199932  2334732      지루함...      0\n",
       "199939  2105796         bad      0\n",
       "199944  2100743     재미없다...      0\n",
       "199946   735755          에혀      0\n",
       "199966  7405830  재미 더럽게없다..      0\n",
       "\n",
       "[5456 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[data.duplicated(['document'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b3ccba9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Id 컬럼의 Na 갯수 : 0\n",
      "Document 컬럼의 Na 갯수 : 8\n",
      "Label 컬럼의 Na 갯수 : 0\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>46471</th>\n",
       "      <td>6369843</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60735</th>\n",
       "      <td>511097</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77665</th>\n",
       "      <td>2172111</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84098</th>\n",
       "      <td>402110</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>127017</th>\n",
       "      <td>5942978</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172375</th>\n",
       "      <td>5026896</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173526</th>\n",
       "      <td>1034280</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197279</th>\n",
       "      <td>1034283</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id document  label\n",
       "46471   6369843      NaN      1\n",
       "60735    511097      NaN      1\n",
       "77665   2172111      NaN      1\n",
       "84098    402110      NaN      1\n",
       "127017  5942978      NaN      0\n",
       "172375  5026896      NaN      0\n",
       "173526  1034280      NaN      0\n",
       "197279  1034283      NaN      0"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(f'Id 컬럼의 Na 갯수 : { len(data[data.id.isnull()]) }')\n",
    "print(f'Document 컬럼의 Na 갯수 : {len(data[data.document.isnull()])}')\n",
    "print(f'Label 컬럼의 Na 갯수 : {len(data[data.label.isnull()])}')\n",
    "\n",
    "data[data['document'].isnull()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9927cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(how = 'any', inplace = True)\n",
    "data.drop_duplicates('document', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e2ccf53",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[~data.document.str.contains('nan')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b28c7859",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data의 크기 : 194542\n"
     ]
    }
   ],
   "source": [
    "print(f'Preprocessed data의 크기 : {len(data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "225cbe1b",
   "metadata": {},
   "source": [
    "## EDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1718989e",
   "metadata": {},
   "outputs": [],
   "source": [
    "naver_review = data['document']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6e8948b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "문장의 최단 길이: 1\n",
      "문장의 최장 길이: 142\n",
      "문장의 평균 길이: 36\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_92/2328176167.py:15: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "min_len = 999\n",
    "max_len = 0\n",
    "sum_len = 0\n",
    "\n",
    "for sen in naver_review:\n",
    "    length = len(sen)\n",
    "    if min_len > length: min_len = length\n",
    "    if max_len < length: max_len = length\n",
    "    sum_len += length\n",
    "\n",
    "print(\"문장의 최단 길이:\", min_len)\n",
    "print(\"문장의 최장 길이:\", max_len)\n",
    "print(\"문장의 평균 길이:\", sum_len // len(naver_review))\n",
    "\n",
    "train_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in naver_review:   # 중복이 제거된 코퍼스 기준\n",
    "    train_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), train_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cc451e89",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "어릴 때보고 커서 다시 봤는데. 진짜 잘 만든 영화였네. 웃음과 감동을 잘 이어 붙였고 정치에 대한 비판이랑 묘사도 굉장히 잘 표현했다. 흥행했었는지 기억은 안나지만 절대 낮은 평점의 영화가 아니라고 생각한다. 연기자들 연기하는 디테일만 봐도 따봉임\n",
      "기억에 남는 장면이 많네요. 그네씬,할배야밤활키는씬,흰한복에화살피, 바다,배도 예뻐요. 또 이렇게 많은 명장면을 남겨주셔서 감사합니다. 보면서 밤볼라, 섬, 봄여름가을겨울그리고봄, 완전한 사육 등의 영화가 떠올랐습니다. 김기덕회고전 홀로 집에서 ㅋㅋ\n",
      "배우들의 표정부터 다른 드라마.일반적인 한국드라마와는 매우 다르고 줄거리도 전혀 어색하지않고 사실적이라 딱딱한 느낌이 든다특히 추적자 이후 발전된 촌철살인은 일정 배경지식을 가지고있어야하고 1회만 놓혀도 갈피를 못잡아서 이런 시청률굴욕을 당하는거같다\n",
      "무간도 3가 이해하기 어렵다 ..3번씩보고 그래도 이해가 안돼면 네이버 해석본봐라 .. 그럼 소름 쫙 돋을거다 니들머리로 해석할려닌까 무간도 3가 그냥 만들어진게 아니고 다 스토리가 이어져있다.. 내가볼땐 무간도 1,3이 진국이다. 니들머리로는 ㅉㅉ\n",
      "시티헌터 다음으로 다시보기에 열중했던 드라마! 회마다 은근한 긴장감과 적절한 코미디를 넣어 무겁지만 가볍게 볼 수 있었던 최고의 드라마였다. 또 드라마답지 않게 스케일도 꽤 커서 보는 사람으로 하여금 박진감도 넘쳤다. 시즌2로 나오면 얼마나 좋을까?\n",
      "두 형제가 겪는 일상에서의 고독과 좌절감을 그린 작품.. 정지된 카메라로 두 남자의 일상을 훔쳐보는 듯한 느낌을 주는데, 주로 롱샷으로 된 화면과 롱테이크기법으로 현대인이 겪는 고독과 소외감을 제대로 살리고 있다. 라스트씬의 롱테이크는 특히 압권..\n",
      "개들에게서 느껴지는 동지애, 협동 정신, 강인한 생존력, 개들을 되찾기 위해 어떤 것도 아끼지 않고 모험을 감행하는 게리 세퍼드의 용기, 기꺼이 그들의 재회를 위해 몸을 아끼지 않고 모험에 동참한 동료 탐험대원들의 기지와 노고에 깊은 경의를 표한다.\n",
      "아무리 생각해도 케이티 홈즈는 니콜키드먼에 비할 바가 못된다. 그녀의 리즈시절 수상작에서, 물랑루즈 피스메이커 투다이포의 엣지있는 모습관 다르게 여기선 수수한 차림으로 나오는데 개인적으로 이렇게 청초한 모습의 본 적이 없다. 여신이다 톰크루즈 xxx\n",
      "아무것도 차려진것이 없는 빈그릇으로도 충분히 배가 부를 수 있다는 걸 깨달았네요. 가뭄에 단비를 내리듯 마음 한구석에서 아기를 품은듯 따듯한 감성이 전달 되었습니다. 높은 자리에 있는것도 아닌데 저절로 무릅 꿇게 만드네요. 많이 반성하고 살겠습니다.\n",
      "필모 보고 캐놀람.. 내가 본 영화가 절반.그 어디에도 이성민은 없었눈뎅....ㅜ.ㅜ 열심히 사는 사람은 말로가 조쿠나.. 골든타임에서 연기력에 놀람.. 사실 스토리보단 이성민 때문에 봄. 마지막 헬기씬.. 환자 가슴에 청진기 대고,,안들려..압권!\n",
      "불현듯 생각나서 다시 봤는데 보면 볼수록 영화와 배우들의 연기가 너무 좋다. 특히 정우성의 영어발음은 몇년 유학다녀온 꽤 지적인 남성의 영어발음이랄까? 과도하게 굴리지 않고 자연스러운 영어구사도 박동하의 성격과 참 잘 어울려서 영화보는 내내 좋았다.\n",
      "꼬마가 너무 귀엽다. 아빠와의 관계가 너무 애틋하고 따뜻해서 영화 전반 내내 엄마미소로 보다가 후반부에서는 그만큼 더 안타깝기도 하고.. 그리고 카메라가 담은 터키의 자연은 정말 굉장하다. 단지 배경이 아니라, 자연이 주인공으로 살아 움직이는 느낌.\n",
      "여기 멍청이들 진짜 많다 ㅋㅋㅋ 물로 왜죽냐 외계인은 분명 물을.얻으로 왓다 하지만 인간의 진화된 세상의 맑은 물은 이미 사라진지 오래다 그걸 보가 알거잇엇자나 어른들은 그냥 장난치는거다 생각햇지만말야 물을얻으로 왓다 오염된물인걸 알게되고 후퇴한거지\n",
      "영화 보고 평 남기기 처음인데, 평점이 너무 낮아서 남긴다 ㅋ 볼만하고 꽤 괜찮았음 그리고 연기자들 모두 연기 잘한다(진짜!! 모두다 10점 만점에 10점) 어쨌든 난 정말 잘봤음!!! 진심이니까 감독님 그리고 주연, 조연님들 모두 모두 힘내세요~!\n",
      "난 이영화 괜찮게 봤는데 왜들 지루하다고 그러지 재밌기만 한데..뭐 샤말란 특유의 반전이나 스릴러적 재미는 좀 약하지만 구성도 괜찮고 특히 영화 특유의 미스테리한 분위기에 묘하게 빠져들던데 여주인공의 순수한 사랑과 희망을 잃지않는 모습도 나름 멋졌고\n",
      "내가 초등학생 때 처음 본 재난영화. 길 가다가 마지막 결말에 사용되었던 베토벤의 알레그레토를 듣고 다시 찾아 보았다. 총 2번, 3번을 넘게 보았지만 어렸을 때 보았던 그 흥분감과 공포, 모든 떡밥들이 회수되는 짜릿함은 여전했다. 최고의 재난영화.\n",
      "대단하다. 배우들의 연기도 그렇고 영화 자체도 그렇다. 많은 생각을 하게 만드는 영화고 효민이가 했던 말, 정구가 했던 말들에 의미가 있을거라 생각하게 된다. 왜 이런말을 했을까? 하면서 생각하는 재미가 있는 영화지만 현실과 닮아서 한편으론 무섭다.\n",
      "세뇌는 없는 사실을 왜곡해서 강압적으로 사상주입을 시키는게 세뇌고 북한 실태를 다룬게 세뇌면 실제 북한이 저러지 않고 평화로운 민주주의 국가라는거냐 저 아래 han0 OO. 지금까지도 강제노역에 인권탄압에 숙청을 강행하는곳이 북한인데 세뇌는 염병ㅉㅉ\n",
      "가장 큰 문제는 배타적 성향이 강한 기독교인들과 사업의 도구로 사용하는 교회가 가장 큰 문제이지 그로인해 본인들도 모르게 타종교인들이 피해를 보고 있다는 현실을 모르는게 가장 큰 문제이지.. 주변에 교회다닌다고.. 그 후 그 사람들의 반응을 보면 답\n",
      "저 이거 예전에 본방 다 사수 햇는데 어제 오늘 문득 다시보고파 전편을 봤는데요. 왜 제겐 4편정도뿐이 기억이 없는걸까요 . 끝은 알면서 다시보고있는듣한 이느낌은 뭐였는지 은수맘 알겠구요 . 최영맘도 알겟어요 왜일까요 .다시 봤지만 정말 잘 봤습니다\n",
      "음....아마 재미가 없으시다고 느끼신 분들은 내용이 완전히 이해가 않가셔서 그러실꺼에요^^ 저도 처음에는 이 영화 도대체 뭐지라고 생각했는데 원작인 책을 끝까지 읽고나니 이해도되고 더 재미있더라고요^^*전 원래 두번 하는거 되게 싫어하는데도 말이죠\n",
      "2007년 시즌 1때부터 즐겨본 유저입니다. 영애씨 나이도 저랑 비슷한 또래라 많이 공감갔는데요. 정말 오랫동안 기다린 드라마네요. 부디 초심 잃지 말고 재밌는 드라마 부탁드립니다. 응원하고 또 사랑합니다. 부디 예전 막돼먹은(?)영애씨가 보고싶네요\n",
      "중학교 고등학교시절 세나와 프로스트 만쎌이 F1레이스를 다투던 기사를 보던게 생생하다.. 특히 멕라렌팀의 흰색과 빨강의 말보로 마킹이된 세나의 머신은 당시 최고로 빠르고 아름다운 아이콘으로 모터스포츠를 좋아하는 사람들의 동경대상이었다.. 아름다운사람\n",
      "평점댓글중 한 댓글보고 글 써요. 그냥 친한친구 두명과 다투고 자살 이걸로만 해석하지 말았으면 합니다. 기태라는 인물에대해 이해도가 부족했다고 생각해요. 그리고 저는 엔딩크레딧 올라갈때의 음악만으로 이 영화의 감정을 충분히 느꼈습니다. 영화잘봤어요.\n",
      "원작은 안봐서 모르겠고..재미와 감동,먹먹함까지 갖춘 잔잔한로맨스..흐름보고 당연히 해피엔딩일줄 알았는데 마지막은 참..그 먹먹함이 아직까지 여운이 남네요.갠적으로 완벽한 내용은 아니였는데 사라맥라클란의 엔젤 이 모자란부분들을 채워줬네요.10점쏩니다\n",
      "데즈카오사무의 만화가 리얼그림체 만화에 밀려서 시시하다고 할때쯤 나온희대의 명작 .... 참고로 오사무선생님은 의사셨고 의학박사 학위를 지내셨던분임 .... 그런사람이 의사를때려치고 아톰 레오 같은 굵직한 명작을 터트리고 마지막에 블랙잭을 그리심 .\n",
      "shy1님답변요1번은 총쏜여자가 목사의 내연녀임 둘이 벗은 사진 나옴 그리고 다시 등장않함 2번은 나비캐릭터 개연성 만들기가 여기서 키포인트 3번은 총은 두발짜리 한발은 동생 한발은 자기를 위함은데 엄마한테 쏘지않고 강간녀쏘면 나비두마리가 날라가면서\n",
      "공정영화심의위원회에서 페어필름(공정영화)마크를 획득한 국내 최초 영화인가?? 영화스태프를 위해 최선을 다한 영화라 그런가~~ 제가 영화를 보면서 흐뭇한 미소를 머금으면서 보게 된 최초 영화같습니다. 앞으로 이렇게 공정하게 잘 만들어진 영화가 마니마니\n",
      "계속 마음 한구석이 계속 울컥하고 쓰리다.. 단지 이런 영화를 대중적이지 못하다고 천대시한 우리 국민들의 영화보는 수준이 더 속쓰릴뿐이다. 현시점에서 앞으로 우리영화는 지금도 미래에도 세계에서 열리는 큰영화제에서 큰상받을일이 없다는게 더 슬플뿐이다.\n",
      "어제우연히티비에서 폴리스스토리4 살짝보다가 아..성룡도마니늙었구나 세월이란..하고생각하다가 폴리스스토리재밌나?하고다운받아봤는데 첨엔넘옛날거라 좀그랬는데보다보니까 빵터지는거많네요ㅋㅋ특히 경찰서에서여러개전화받는거랑 장만옥이오토바이타는거ㅋㅋ암튼재밌게봤다ㅋ\n",
      "지영이가 울었으면 좋겠다고 생각했다. 이상하게 태희가 만두를 사는 장면에서 눈물이 났다. 막 슬픈 건 아닌데 태희가 슬퍼해줘서 울은 것 같다. 사실 10점은 아닌데 20살이 돼서 이 영화를 보면 10점을 줄 것 같아 미리 준다. 언니들 잘 살고있죠?\n",
      "너무 현실적이어서 많이 놀랬다. 영화를보고 깨달은게 있다면 사랑엔 분명 책임이 존재한다는것 사랑하고 사랑해주는 사람이 있다면 참는것부터 하자... 이정현의 대사가 어색한부분도 있었지만 번지르한 대사보다 현실에대한 언어가 작품을 더욱 완성도를 높였다.\n",
      "막완전 으스스하고 그러진않지만 소재가 좋다 우리나라 일베하며 페이스북에서의 마녀사냥등 여기저기 정신이상한 사람들의 남 생각안하는 댓글들 그리고 행동들 정신차리고 살기를 바란다 이렇게 당하고 싶지않으면(개인적으로 저게 귀신이아니라 사람이었으면 재밌었을\n",
      "톰크루즈의 기본재미 보장이라는것을 생각하자 엄연히 다른 장르임에도 첩보물=제임스본, 본드 자연스레 연결지어서 재미를 반감시키는 평론가 싸구려 평은 잊어라 배우와 스토리를 적절하게 잘 배치해 레드의 시원함미스터앤미세스의 통쾌하게 짜여진 이벤트같은 영화\n",
      "엔젤을 어디에서 봤나 했더니 번개도둑에 출연했었군요。단역이였지만 말이죠 하하 루카스는 나름 이름이 알려진 배우라서 다들 잘 알고 있으리라 생각합니다。월드인베이젼、엑스맨、한나몬타나 등 다수의 영화에 출연했었죠。무료한 주말 시원하게 감상하시기 바랍니다！\n",
      "내가 영화제작자라면,감독 얘 당장 데려다가 메이저영화로 데뷔시킨다.그것도 액션영화.잘만든 영화보다 더 재밌는 다큐는 정말 쉬운게 아냐.이정도면 특별한 능력으로 인정해줄만함.개인적으로는 수퍼피쉬나아마존의눈물이상 좋았다.앞으로가 더 기대되는 수퍼루키등장\n",
      "겨울왕국만큼 화려하지는 않지만 보고 나면 여운이 길게 남는 영화. 특히 도제가 텐진을 태우고 절벽을 뛰어넘으며 보인 눈빛에 가슴이 먹먹해졌다. 어떻게 물감으로 저런 눈빛을 표현하지?? 집으로 오면서 새삼 놀라웠다. 5살 아들에게는 조금 어려운 애니.\n",
      "내가 고백을 하면.. 이영화 보고 찾아보게된영화다 그영화안에 이영화가 등장한다는// 여주가 무슨영화가 먹기만하냐고함ㅋ 이런 소소하고 편한하게흘러가는 영화가 좋다 이영화에서도 내가고백을 하면이란 영화에서도 강릉과 커피숍이 나온다 결론은 강릉가고싶다는거\n",
      "인간의 감정을 갖은 로봇을 1회용으로 치부해버리는 그저 돈벌이로만 이용하는 이기적인 인간의 모습을 비판하려하는거같다.로봇의 등장으로 사소한잘못과 사생활 침해문제를 다룬 그저그런 액션영화가아닌 탄탄한시나리오 연기등등 근래에 보기어려운 수작임은 분명하다\n",
      "말하는 이와 듣는 이가 분별되는지, 주는 자와 받는 자가 다른건지, 배우는 자와 가르치는 자가 있다는 건지,,,누가 미치고 누가 온전하다는 거야,,,언제나 어디서나 내 자신만을 본다,,,우린 누구나 분열 되어 있고,,,그래서 누구나 다 미친 것이다.\n",
      "쉽게 접할수 없었던 존재이자 주제에 초점을 맞춘것에 일단 높은 평가를 두고요..분단국가로 이념차이가 분명한 한국의 입장에서 보기에 여러 생각을 하게합니다. 일본에서 태어나 조총련계 학교를 다니는 아이들 마음속에 정체성이라던가 여러 고민이 있을것같네요\n",
      "별로 안끌려서 미루다가 봤는데 인생영화됬어요.. 노래,대사,풍경,할머니,아만다 그리고 처음엔 별로였던 츤데레 남주까지 다 완벽하네요 그냥 너무 예쁜영화. 여자분들이면 무조건 보시길 특히 마지막에 남주가 only lips ..하는 장면 아 또볼거야 .\n",
      "선정적인걸로만 알고 또, 그렇게 (선정적인 걸로) 알려져 있어서 보지 않았던 영화.그러나, 영화를 보는 것과 일부만 보는 것은 완전히 다르다는 것을 느끼게 해준 영화입니다. 차라리, 포스터에 선정적인 것이 다 없거나, 그렇게 선전되지 않았다면....\n",
      "10점도 아깝다 이 영화를 이제 본 내가 원망스럽다 정말와 일본 애니 남주들은 진짜 하나 같이 다 짱이고 이 영화는 정말 정말 말로 표현할수없음 하울이랑 결혼하라하면 하겠어 진짜 시간을 달리는 소녀처럼 재밌는 영화다 와 평점이 140자 까지인게 싫다\n",
      "소소한 일본식 코믹요소와 반복된 일상에 비범해보이는 남들의 삶을 부러워하던 내모습이 공감되며 평범함에 대한 새로운 시각과 공작은 화려하지만 그 화려함 때문에 결국 우리(감옥)에 갇히고 참새는 평범하지만 자유롭게 날아가는(비행기) 엔딩장면이 인상깊었다\n",
      "정말 재미있어요.지금1편부터 끝까지 디시보고있는데 진짜 재미있어요.그리고 밑에분들 중에서 욕하신 분들 욕하지마세요.님들이 배우들보다 연기 잘하시나요?못하시면서 욕하지마세요.님들은 유명하지도 않잖아요.저 신고 할려하다가말았어요.욕하지마세요.강소라 짱!\n",
      "두뇌와 가슴이 없이 눈으로만 보는 무지한 사람들에게는 지루하고 돈만 날릴영화겠지. 그런부류는 그냥 치고받고하는 헐리욷 쓰레기 영화나 보길. 왜 이런영화를 돈들이고 시간 낭비하며 보러갔는지 이해가 안감. 명화를 보며 만화만도 남도 못한 쓰레기라 할게지\n",
      "영화에 나온 여선생님 같은분이 고등학교시절 제게도 있었습니다. 저도 사고를 참 많이치던 학생이었습니다.그분은 항상 제편을 들어주셨었습니다.아버지도 제편이아니었고 어머니도 같이있지않을때 끝까지 제편이었던선생님.재대후 연락끊긴 선생님 보고싶습니다..ㅜㅜ\n",
      "영화는 아직 안봤지만, 원작을 워낙 재미나고 감동적이였기에 10점을 주고본다. 설정이 어쩌고 하지만... 이건 영화다. 애니다. 그딴소리 할꺼면 수학책이나 읽어라. 역사도 거짓에 외국 투성이니까. 그리고, 일본은 정말 책 많이 읽는다. 너 책은읽니?\n",
      "브누와 쟉꼬 감독이 연출한 이색적인 스릴러틱 로맨스. 영화에 깔리는 사운드 트랙은 인물들의 관계와 이를 바라보는 관객들을 더욱 불안하게 만든다. 안티크라이스트와 멜랑꼴리아를 통해 인상깊은 연기를 선보인 샤를로뜨 갱스부르는 이영화에서도 여전히 빛난다.\n",
      "에릭은 당연히 나왔어야 했다. 완벽한 삶을 쫒는 이병헌, 허나 사람은 자기 인생이 가장 소중하고 제일 중요하다. 여기 나오는 모든 애들이 다 자기 잇속만 챙긴다. 에릭 또한, 자신의 복수를 위해서 이병헌이 뭔 짓을 하건 상관없이 죽인 것.이게 삶이다\n",
      "1982년 작 맞나?! 테일러 핵포드 감독 최고의 마스터 피스! 주제곡 Up Where We Belong과 절묘하게 맞아 떨어지는 엔딩 장면과 사관 학교 졸업 장면의 세련된 미장센이 주는 아찔함과 아련함이란..『칼리토』와 더불어 최고의 영상 미학!!\n",
      "이 영화 쓰레기다 한 사람들은 처음부터 보지를말아야지 포비아면 포비아답게 그렇게 혐오만 하면서 사세요. 성적소수자들도 인정 못하면 개방적인 사고로 어떻게 세상을 살아갑니까. 그따위 말로 소수자들을 상처주지마세요. 사람을 사랑하는건 당연한 권리입니다.\n",
      "가벼운 사랑이야기였다면 그냥 그런 드라마였을텐데, 저는 오히려 좀 대사 하나하나에서 전율이 느껴지더군요. 오히려 생각할 거리를 많이 던져 주는 드라마 같습니다. 그냥 순수한 '순정만화 주인공' 같은 이야기야 많잖아요? 오히려 예전의 틀을 깬 데 점수\n",
      "맥클레인과 그랜트는 특수부대를 이끌고 그 교회를 포위하나, 이미 탈출준비를 해 놓은 스튜어트 일당은 스노우모빌을 이용하여 747 점보기가 준비된 곳으로 빠져나간다. 이번에도 죽을 뻔하다 살아난 맥클레인은 그들이 떨구고 간 총에 공포탄이 들어있는것잼~\n",
      "인간이 닥친 한계에 얼마나 극단적으로까지 극복하느냐를 다룬 영화. 다소 이해하긴 힘들 수 있으나, 영화가 끝난후에 곱씹어보면 대충 내용을 알 수 있음. 나머지 사람들의 능력들을 보여주지 않았던 것은, 그들이 그상황을 극복할 의지가 없었기 때문.10점\n",
      "좀비라고 하면 공격성향 강한 끔찍한 이미지가 그려지는데 이 영화에서는 오히려 사람들에게 이용의 대상이 되는 그런 좀비의 모습이 담겨있어요.영화보는 내내 감정이 오묘해지는게 슬프더라구요. 새롭게 해석되고 그려진 좀비영화가 궁금하신분들은 꼭 보세요!!!\n",
      "때는 2년전, 반전영화 매니아로써 엥간한 이름난 작품은 거의 다봤다고 자부할때쯤 우연히 아무스토리도 모른채 보게된 이 영화는 진짜반전에 목말라있던 나의 뒤통수를 오지게 후려갈겼다. ost부터 구성, 연기력, 스토리, 화면, 그 어느하나 뺄게없는 명작\n",
      "전쟁이 끝낫지만 여전히 이념의 굴레를 벗어나지 못하는 여전히 전쟁중인 끄라이 사람들, 나치치하릐 수용소 경력이 파쇼와 결탁한 것을 교화형을 사는 끄라이 사람들 무책임하고 무능한 국가의 희생자들 그들이 자유를 얻는 방법은 기관차를 달리는 것 오직 그것\n",
      "혁명, 그 자체다. 한국드라마의 혁명. 시즌제 한국 드라마의 가능성을 보여준 작품이자 한국의 무한한 가능성을 보여준 작품. 작가는 최근에 굿닥터로 대박난 분, 류덕환 & 안용준의 수준급 연기력까지.. 내 인생 최고의 한국시리즈란 말 밖에는 할말이..\n",
      "바다를 보러 오기까지 위험천만한 일 투성이었다. 경찰과 갱에 쫒기고 은행을 털고 인질극을 벌이기도 하고... 그런 과정을 겪었는데 더 두려울께 있나? \"두려울 것 하나도 없어.\" 내일 내가 죽는다면 오늘 나는 무엇을 해야하는가? 바다, 데낄라, 담배\n",
      "정말 아름다운 드라마이네요 대사하나하나에 공감하며 울고웃으며 첫화부터 쭉 시청해왔어요 이런거안남기는데 드라마퀄리티에비해 흥행이잘안된거같아 아쉬움에 남깁니다 다음에도 아름다운이야기써주세요 작가님! 연기자분들 역할호응도가 대단했습니다! 모두수고하셨어요~\n",
      "상처를 어떻게 극복해가는지 어른들을 위한 성장드라마..가족,이웃과 함께 살아가는 방법을 찾아주는 간만에 정말 따듯한 드라마! 빼놓치않구 챙겨보는 1인입니다^^ 인물하나하나 캐릭터가 녹아잇구 자극적인 막상드라마와는 차원이 다른 유나의 거리 사랑합니다♥\n",
      "역사왜곡/고증문제는 논외로 치고, 최고의 정치사극이 아닐까 싶음. 정치에서 선악이란 없다, 정치판에서 영원한 적은 없다란 말을 가장 완벽하게 표현해낸 드라마인듯. 모든 사건의 중심이 각각의 정치세력이 추구하는 가치관의 대립이란것에 촛점을 맞춘 걸작~\n",
      "Com-한순간도 긴장을 늦출수 없는.. 세월이 지나도 명작은 명작.. 낯선곳에서는 낯선자를 조심하라.. 한성격하는 커트형님의 찌질 처절한 모습.. 목소리 좋은 월시아자씨는..넘 일찍 가셨네.. 아무것도 아닌 여주인공에 매력을 느끼는 이유는 뭘까..?\n",
      "주인공 보는 내내 잭 그레인키가 떠올라서 집중이 조금 안됐던영화. 개인적으로 사장으로선 할만큼 했다고봄. 인도 꼬붕놈이 너무 욕심을 부린게 잘못인거지 멍청한놈을 그때까지 안짜르고 써준것만으로도 충분히 배려심 있었다고 보고 부대표까지 승진시켜줬건만ㅉㅉ\n",
      "벤허 역은 말론 브란도도 탐냈던 배역인데 190cm의 찰톤 헤스톤 보다 175cm의 차돌 같은 말론 브란도가 더 어울렸을 듯! 만약이란 건 없지만 말론 브란도가 벤허 역을 했다면ㅎㄷㄷ 말론 브란도는 나이 50도 되기 전에 아카데미 남우주연상 3개네!\n",
      "태상몰래 강제키스하고 셔츠찢을때가 스릴있고엄청 재밌었는데.키스신보고 잠못이뤘다.ㅋㅋㅋ재미로 보면되지 너무 심각하게 받아들일필요는없을거같은데 시청자의견때문인지 나중에는신세경이연우진만 바라보니 재미없었음.너무빨리끝나서 아쉽다 ㅜㅜ결말도훈훈하고좋았었음^^\n",
      "애들이 우는장면 하나없는데도 가슴이 먹먹하다..아빠는 어디가고 엄마는 어디가고..어린나이에 가장이되고 엄마가 할일을 하는게 얼마나 힘들었을까.우리나라도 애들 다 잘먹고 잘지내고 있는거 같지만 복지카드로 편의점 삼각김밥만 겨우 사먹는 애들도 있던데 휴\n",
      "임창정 영화중에 젤좋은 영화다 한가지 안타까운건 이좋은 영화를 홍보나 포스터 등으로 저렴하게 만들어버린 마케팅에 문제가 있었다고 본다 나도 당시에포스터보고 또 저렴한코메디 영화구나 싶어 안봤다가 지금에서야 봤다 아니였으면 흥행도 잘됐을텐데 아쉬움ㅠㅠ\n",
      "나에게 뮤지컬영화라는 장르의 재미를 처음 맛보게한 영화. 음악이 주가 되는 영화는 편견이 있었기 때문에 보기 전에도 색안경을 쓰고 봤었다. 하지만 노래로 밖에 표현이 안되는 영역이 있는 법. 원작의 힘도 크겠지만 가사의 재치와 배우의 열연이 시너지.\n",
      "처음한 연기는 어색하다. 가수가 이정도면 잘했다. 보아에게 왜 14년차 연기자의 모습을 바라는가? 보아는 14년차 가수다. 고작 1년한 연기자이다. 1년짜리 신인에게 왜 중견연기자의 모습을 보여달라고 하는가? 보아는 중견가수이지 중견연기자가 아니다.\n",
      "평점 박하네. 10점 스케일이다. 이 영화를 왜 이제본거지. 이 영화를 필두로 대륙 전쟁 영화를 섭렵해봐야겠다는 생각이드네. 이런 장르 불호였는데. 완전 극호됐음♥처음엔 양조위만 눈에 들어오다가 나중엔 조조 제갈량 관우 등 모든 캐릭터가 다 멋져보임\n",
      "늑대인간설정은 조금에러긴하다 평점글처럼 좀 비중있으면또모를까 후속작 2탄이 나오면또모를까 근데 마지막 끝날때 여자의사 눈 번쩍뜬거보니 마치 그뒤 내용 후속작이 나올것만같은느낌ㅋㅋ나오진안겠지만...암튼 개인적으로는 재밌게봤다 퀄리티도 나쁘지않다고생각함\n",
      "솔직히 좀 무서워서 볼륨 작게 해서 본 영화. 엑스맨 시리즈의 로그 역을 맡았던 안나 파킨이 주연으로 나오는데 그 와중에도 눈이 가더라는. 일식과 인간을 속여 죽음으로 빨아들이는 악마. 마지막 7번째 아이에 대한 관객 예상 뒤집기 등 볼만한 공포물.\n",
      "오늘 여섯살 아들과 보고 왔어요. 아들 첫 극장 관람이라 너무도 재밌게 보았다고 하네요. 완전 컬러풀한 에니가 아니고 그림이나 느낌이 참 감성적으로 다가왔어요. 애들 엄마로써는 참 좋았구요. 애들에게 딱 맞는 대사와 전달. 생각지도 않고 봤는데 ^^\n",
      "아 줫나 신선하게 보고있다가 공포호러로 바뀌어서 개 식겁하면서 봤네 sf 인줄알았는데 스릴러에 가까워짐 ㅋㅋ 거기까진좋다이거야 ㅠㅠ 하지만 마지막 커플은 끝까지 살려두지 에휴... 로맨스는 전혀없고! 그래서 1점감점 아쉽다정말 ㅠ 로맨스만살리지 ㅠㅠ\n",
      "영화에서 나왔던말중에.. 사랑은 행복한 만큼 이별이란 것이 다가왔을때 그 아픔이 배가 되는것이다.. 필자도 그 이별의 아픔이 두려워서.. 사랑하는걸 무서워 하고 멀리하고 있지만.. 주변에 윤지호 같은 친구 있었으면 좋겠네요 암틈 무지 재밋었습니다..\n",
      "너가 제일좋아하는영화라고해서 보았고 너가 제일좋아하던책도읽고 책작가에 대해서도 더 알아봤다 공감했다던 그드라마도 봤고 견자를 더 알기위해 랭보를 찾고 책도사서읽었다. 너를더알고싶었고 너에게맞는사람이되고싶었다 너가 읽다만 나라는책의 내용을 더채우고싶다\n",
      "인간의시간여행에 대한 의미있는 메세지도 담고있을뿐더러 시간파라는과학적장치로 더볼만했고진화는 파충류의 승리같은느낌.발에밟힌 나비도 나비효과를 상징적으로 말해주는것같고 사소한것하나도 시간의 끝엔 사소한게 아니다 시간여행이가능해져도 막자 핵과 원자력처럼요\n",
      "여주인공은 아름다움 여신 그 자체였다. 저승사자와의 산으로가는 러브스토리로 중간에 매우 혼란스러웠으나 천녀유혼이 내게 깊은 감명을 주었던 어린 시절에 비해 지금의 내가 나이든 탓인것 같다. 순수한 마음으로 본다면 가슴설렘을 듬푹 품을 수 있는 영화다\n",
      "진정한 고통이 뭔지를 알려주는 영화.. 명불허전 류승범 보는 맛에 영화가 한층 업 됐다. 말이 안 되는 부분이 다소 있긴 했으나 이 영화가 주는 의미가 무엇인지는 충분하게 느껴졌기에 언급하지 않으련다. 조금은 색다른 느낌의 복수극, 즐겨보길 바란다.\n",
      "별 기대없이 그냥 크리스콜퍼가 나온다고해서 봤다가 의외의 무언가를 얻었다. 뻔한 이야기일거라 생각했는데 지나치게 현실적인듯하면서도 교훈을 주는 영화. 단순히 수동적으로 인생을 살고있던 나에 대한 반성을 하게까지한다. 우리 모두를 위한 영화가 아닐까?\n",
      "애정 멜로 안 조아하는데여 영화 초반 남주아역 연기가 참...ㅠ 다섯번봤는데 봐두 봐두 첫사랑을 대하는 소년의 솔직한 내면 외면.. 대사 하나하나 쏙쏙 아련히... 법정에서 눈물... 감동입니다. 이런 애잔한 사랑두 있구나 잉그리쉬페이션트 후 감동~\n",
      "인생 최고의 드라마라고 말할 수 있을 정도로 따뜻하고 위로를 주는 드라마에요. 수영씨도 연기 너무 잘하고 감우성씨는 역시 최고구요. 모든 주조연을 비롯한 작가님 감독님까지 너무 좋은 들마.아마 본방사수 못한걸 후회하면서 다운 받아보는 분들 많을듯^^\n",
      "요즘엔 운널사 덕분에 행복한한주를 보내여!!..장혁씨의 연기력에 늘 박수를 보내며 스토리 진짜 짱!!!!..장나라씨도 넘 이쁘고 착하구 연기도 잘하시구,,조주연분들역시짱..나쁜 악역이 판치지않아 보는내내 힐링+해피랍니다...ㅎㅎ이런좋은잘품볼수있어쌩유\n",
      "창공으로 옛조선 우리나라의 조선기술과 같이 창공으로 날으는 전투기도 우리나라 최고의기술력을 보여준 영화가아닌가싶네요 보는내내 박진감넘치고 스펙터클한 비행은 가히 세계최고라꼽을수있습니다140자평으로는 말로도 다표현하지 못할영화 직접 눈으로 감상하세요!\n",
      "괴수 영화는 1. 도시가 부서지는 장면 1. 괴수와 군과의 전투씬 3.납득가는 괴수 발생과 주인공 동선 4.그 속에서 살아 남으려 하는 사람들 정도가 솰아있어야 한다.수작이다. 또 봤는데 또 보고싶음. 평점 낮은 이유는 아마 1인칭시점 적응 못한인간\n",
      "단 한순간도 지루한 장면이 없다는 게 이 영화의 가장 큰 장점.감독의 연출력이 장난아닌듯~어릴 때 보고 스토리가 충격이라 인상에 강하게 남아있었는데, 이번에도 정말 시간가는 줄 모르고 몰입해서 봤다. 악역과 싸우는 씬만 빼고는 전체적으로 완벽한 영화\n",
      "지금까지 본영화중에 이 아들이 제일좋다 모든게 패스트함 다른영화였음 차로 벽에 심하게 부딪혔을때 만날 정신쳐잃어가지고 부모가 업고가거나 그러는데 얜 엄마가 괜찮냐하니까 바로 예스!!!! 졸라맘에듦 주사도 전혀망설임 없이 놔주고..1점은 마지막이...\n",
      "캐슬린 비글로우는 특별한 재능의 소유자라는것을 유감없이 과시하는 수작,그녀가 스케일에 함몰되지 않고,계속 자신만의 길을 찾아갔으면 한다.개인적으론,존 코너엄마 사라코너역할에,최고적임자라고 생각하는편.팔뚝알통좀 한번 봐라.1000년쯤 따라 다니고 싶다\n",
      "정말 소장하면서 평생을 다시 보아야할 영화라 생각합니다.. 90년대 초반 디테일하게 평가한다면 조잡한 부분다 적지않지만..전체적인 스토리.. 그리고 결정적으로 임청하와 장국영님의 눈빛 표정연기력과 적절히 흘러나오는사운드효과는 평점10점도 모자란느낌임\n",
      "대선 직후에 이 영화를 보게 돼서 여운이 길게 남았습니다. 사실 줄거리 자체만 놓고 보면 이전의 소설이나 영화에서 많이 사용된 내용의 반복이라고도 볼 수 있지만 개성 강한 인물들의 흡입력 있는 연기 덕분에 새로운 내용의 영화로 재탄생된 것 같습니다.\n",
      "우리가 사랑할 수 있을까! 진짜 이 드라마 강추합니다!!! 배우들의 연기도 너무 좋고, 감독님의 연출과 작가님의 대본도 너무 좋아요!! 요즘 우사수 보는 재미에 푹 빠졌어요!! 제가 지금까지 본 드라마 중에 제일 재밌는 공감이 많은 드라마입니다!!!\n",
      "이 영화를 아무런 준비도 없이 보기 시작했던 저는 잠시후 영화가 주는 무게감에 짓눌렸습니다. 우린 지금 삶을 별다른 생각없이 흘려보내고있지않을까요? 모든 순간은 소중한데말이죠. 이 영화를 본 후엔 매 순간을 좀 더 소중히 생각하며 살게되더군요....\n",
      "세상의 제일 어두운 곳에서 정말 비참한 연명을 하면서 사는 사람들. 같은 인간으로서 어떻게 그럴 수 있을까하면서 한시간을 보고, 그들에게 관심을 갖는 사람을 보며 한시간을 봤다. 이런비극이 일어나지 않기를, 우리주위 사회 그늘 속 사람들을 잊지말길.\n",
      "이 명작을 이제야 본 내가 한심하네... 이 영화를 모티브로 한 연극 때매 관심이 생겨서 봤는데... 이건 관객을 위한 영화가 아니네 그놈을 위한 영화다. 그 자식이 이걸 꼭 봤으면 싶고 이 사건을 알게 됨으로써 또다시 신은 없다고 느낀다. 화가난다\n",
      "https://t1.search.daumcdn.net/thumb/C110x160.q70/?fname=http%3A%2F%2Fcfile78.uf.daum.net%2FC110x160%2F195D724D50ECD8281116E2Total:조삼모사바나나백신\n",
      "진짜 잼섯 너무재밋어서 책까지봣는데 나는 영화가 더잼드라 몰르고봐서그런지 근데 또책보니까 영화보면서 의아해했던부분이나 세부적인내용까지다나와서잼섯 ㅋ 근데 왠지모르게 책에 캣니스는 성격이 좀더 소녀다운 그나이다운 느낌이고 영화는아무래도 성인스럽달깤ㅋㅋ\n",
      "화려한 영상미는 없어요. 아 이게,여기가 몽골이구나 하는 장면들이 쏟아지죠. 이 거대한 이야기를 단순하게 간단하게 이렇게 표현한게 오히려 대단하다 여겨지죠.몽골인의 삶이, 몽골 남자와 여자의 삶이,징기스칸의 생애의 한순간을 덤덤히 보았어요.실감나게!\n",
      "공산당의 과오에 대한 직접적인 언급을 피하고 있지만 당시 극단적 좌경향 시대가 남긴 상처들을 평범한 가족의 눈으로 잘 묘사하고 있다. 그리고 마지막 장면을 통해 감독이 강조하고 있는 전통의 회복은 곧 사상으로 얼룩진 인생의 회복을 의미하는게 아닐까.\n"
     ]
    }
   ],
   "source": [
    "def check_sentence_with_length(raw, length):\n",
    "    count = 0\n",
    "    \n",
    "    for sen in raw:\n",
    "        if len(sen) == length:\n",
    "            print(sen)\n",
    "            count += 1\n",
    "            if count > 100: return\n",
    "\n",
    "check_sentence_with_length(naver_review, 139)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3d6f9f0",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_92/148705089.py:9: DeprecationWarning: `np.int` is a deprecated alias for the builtin `int`. To silence this warning, use `int` by itself. Doing this will not modify any behavior and is safe. When replacing `np.int`, you may wish to use e.g. `np.int64` or `np.int32` to specify the precision. If you wish to review your current use, check the release note link for additional information.\n",
      "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
      "  train_length = np.zeros((max_len), dtype=np.int)\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "max_len = 150\n",
    "min_len = 10\n",
    "\n",
    "# 길이 조건에 맞는 문장만 선택합니다.\n",
    "filtered_data = data[(data['document'].str.len() < max_len) & (data['document'].str.len() >= min_len)]\n",
    "\n",
    "# 분포도를 다시 그려봅니다.\n",
    "train_length = np.zeros((max_len), dtype=np.int)\n",
    "\n",
    "for sen in filtered_data['document']:\n",
    "    train_length[len(sen)-1] += 1\n",
    "\n",
    "plt.bar(range(max_len), train_length, width=1.0)\n",
    "plt.title(\"Sentence Length Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "fc49374c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filtered data의 크기 : 181695\n"
     ]
    }
   ],
   "source": [
    "print(f'Filtered data의 크기 : {len(filtered_data)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1119cee1",
   "metadata": {},
   "source": [
    "## SentencePieceModel tokenizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c31fcd37",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "30275883",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/nsmc/ratings.txt.temp --model_prefix=kor_spm_unigram_8k --vocab_size=8000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/sp_tokenizer/data/nsmc/ratings.txt.temp\n",
      "  input_format: \n",
      "  model_prefix: kor_spm_unigram_8k\n",
      "  model_type: UNIGRAM\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/nsmc/ratings.txt.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 181695 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=7111188\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1715\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 181695 sentences.\n",
      "unigram_model_trainer.cc(139) LOG(INFO) Making suffix array...\n",
      "unigram_model_trainer.cc(143) LOG(INFO) Extracting frequent sub strings...\n",
      "unigram_model_trainer.cc(194) LOG(INFO) Initialized 382219 seed sentencepieces\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 181695\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 443679\n",
      "unigram_model_trainer.cc(489) LOG(INFO) Using 443679 sentences for EM training\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=192030 obj=15.3971 num_tokens=1050540 num_tokens/piece=5.47071\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=177439 obj=14.3077 num_tokens=1057069 num_tokens/piece=5.95737\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=133008 obj=14.3884 num_tokens=1099973 num_tokens/piece=8.26998\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=132780 obj=14.3362 num_tokens=1100441 num_tokens/piece=8.2877\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=99580 obj=14.5497 num_tokens=1152927 num_tokens/piece=11.5779\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=99569 obj=14.4932 num_tokens=1153083 num_tokens/piece=11.5807\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=74676 obj=14.7265 num_tokens=1202997 num_tokens/piece=16.1096\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=74675 obj=14.6711 num_tokens=1203009 num_tokens/piece=16.1099\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=56006 obj=14.9396 num_tokens=1256544 num_tokens/piece=22.4359\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=56006 obj=14.8806 num_tokens=1256568 num_tokens/piece=22.4363\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=42004 obj=15.1764 num_tokens=1310896 num_tokens/piece=31.2088\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=42004 obj=15.1146 num_tokens=1310946 num_tokens/piece=31.21\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=31503 obj=15.4405 num_tokens=1367496 num_tokens/piece=43.4084\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=31503 obj=15.3726 num_tokens=1367491 num_tokens/piece=43.4083\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=23627 obj=15.7332 num_tokens=1427966 num_tokens/piece=60.4379\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=23627 obj=15.6578 num_tokens=1427993 num_tokens/piece=60.439\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=17720 obj=16.0553 num_tokens=1492220 num_tokens/piece=84.2111\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=17720 obj=15.9698 num_tokens=1492252 num_tokens/piece=84.2129\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=13290 obj=16.3996 num_tokens=1560735 num_tokens/piece=117.437\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=13290 obj=16.2964 num_tokens=1560848 num_tokens/piece=117.445\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=9967 obj=16.7707 num_tokens=1633244 num_tokens/piece=163.865\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=9967 obj=16.6634 num_tokens=1633256 num_tokens/piece=163.866\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=0 size=8800 obj=16.8878 num_tokens=1666375 num_tokens/piece=189.361\n",
      "unigram_model_trainer.cc(505) LOG(INFO) EM sub_iter=1 size=8800 obj=16.8397 num_tokens=1666788 num_tokens/piece=189.408\n",
      "trainer_interface.cc(615) LOG(INFO) Saving model: kor_spm_unigram_8k.model\n",
      "trainer_interface.cc(626) LOG(INFO) Saving vocabs: kor_spm_unigram_8k.vocab\n",
      "sentencepiece_trainer.cc(177) LOG(INFO) Running command: --input=/aiffel/aiffel/sp_tokenizer/data/nsmc/ratings.txt.temp --model_prefix=kor_spm_bep_8k --model_type=bpe --vocab_size=8000\n",
      "sentencepiece_trainer.cc(77) LOG(INFO) Starts training with : \n",
      "trainer_spec {\n",
      "  input: /aiffel/aiffel/sp_tokenizer/data/nsmc/ratings.txt.temp\n",
      "  input_format: \n",
      "  model_prefix: kor_spm_bep_8k\n",
      "  model_type: BPE\n",
      "  vocab_size: 8000\n",
      "  self_test_sample_size: 0\n",
      "  character_coverage: 0.9995\n",
      "  input_sentence_size: 0\n",
      "  shuffle_input_sentence: 1\n",
      "  seed_sentencepiece_size: 1000000\n",
      "  shrinking_factor: 0.75\n",
      "  max_sentence_length: 4192\n",
      "  num_threads: 16\n",
      "  num_sub_iterations: 2\n",
      "  max_sentencepiece_length: 16\n",
      "  split_by_unicode_script: 1\n",
      "  split_by_number: 1\n",
      "  split_by_whitespace: 1\n",
      "  split_digits: 0\n",
      "  treat_whitespace_as_suffix: 0\n",
      "  allow_whitespace_only_pieces: 0\n",
      "  required_chars: \n",
      "  byte_fallback: 0\n",
      "  vocabulary_output_piece_score: 1\n",
      "  train_extremely_large_corpus: 0\n",
      "  hard_vocab_limit: 1\n",
      "  use_all_vocab: 0\n",
      "  unk_id: 0\n",
      "  bos_id: 1\n",
      "  eos_id: 2\n",
      "  pad_id: -1\n",
      "  unk_piece: <unk>\n",
      "  bos_piece: <s>\n",
      "  eos_piece: </s>\n",
      "  pad_piece: <pad>\n",
      "  unk_surface:  ⁇ \n",
      "}\n",
      "normalizer_spec {\n",
      "  name: nmt_nfkc\n",
      "  add_dummy_prefix: 1\n",
      "  remove_extra_whitespaces: 1\n",
      "  escape_whitespaces: 1\n",
      "  normalization_rule_tsv: \n",
      "}\n",
      "denormalizer_spec {}\n",
      "trainer_interface.cc(329) LOG(INFO) SentenceIterator is not specified. Using MultiFileSentenceIterator.\n",
      "trainer_interface.cc(178) LOG(INFO) Loading corpus: /aiffel/aiffel/sp_tokenizer/data/nsmc/ratings.txt.temp\n",
      "trainer_interface.cc(385) LOG(INFO) Loaded all 181695 sentences\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <unk>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: <s>\n",
      "trainer_interface.cc(400) LOG(INFO) Adding meta_piece: </s>\n",
      "trainer_interface.cc(405) LOG(INFO) Normalizing sentences...\n",
      "trainer_interface.cc(466) LOG(INFO) all chars count=7111188\n",
      "trainer_interface.cc(477) LOG(INFO) Done: 99.9501% characters are covered.\n",
      "trainer_interface.cc(487) LOG(INFO) Alphabet size=1715\n",
      "trainer_interface.cc(488) LOG(INFO) Final character coverage=0.999501\n",
      "trainer_interface.cc(520) LOG(INFO) Done! preprocessed 181695 sentences.\n",
      "trainer_interface.cc(526) LOG(INFO) Tokenizing input sentences with whitespace: 181695\n",
      "trainer_interface.cc(537) LOG(INFO) Done! 443679\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=94781 min_freq=99\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=14330 size=20 all=123321 active=11620 piece=▁어\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=11586 size=40 all=128404 active=16703 piece=▁1\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=8386 size=60 all=132145 active=20444 piece=▁생\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=6874 size=80 all=136450 active=24749 piece=▁생각\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=5463 size=100 all=140649 active=28948 piece=이라\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=5447 min_freq=83\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4769 size=120 all=143920 active=9762 piece=▁배우\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=4239 size=140 all=146788 active=12630 piece=적인\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3720 size=160 all=149738 active=15580 piece=▁예\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3484 size=180 all=152060 active=17902 piece=▁바\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=3122 size=200 all=154976 active=20818 piece=▁이건\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=3120 min_freq=74\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2912 size=220 all=157402 active=10105 piece=▁때\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2741 size=240 all=160816 active=13519 piece=인데\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2497 size=260 all=164260 active=16963 piece=▁강\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2367 size=280 all=167235 active=19938 piece=▁우리\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2211 size=300 all=169099 active=21802 piece=▁아이\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=2204 min_freq=67\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=2044 size=320 all=171272 active=10535 piece=▁그런\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1911 size=340 all=173430 active=12692 piece=재미\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1833 size=360 all=176210 active=15472 piece=▁무슨\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1740 size=380 all=178946 active=18208 piece=▁몰입\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1649 size=400 all=181247 active=20509 piece=보는\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1640 min_freq=61\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1590 size=420 all=183482 active=10993 piece=▁20\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1539 size=440 all=184892 active=12403 piece=▁억\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1459 size=460 all=187154 active=14665 piece=▁음악\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1407 size=480 all=189223 active=16734 piece=▁필요\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1350 size=500 all=191194 active=18705 piece=들을\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1348 min_freq=57\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1291 size=520 all=193096 active=11175 piece=▁파\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1226 size=540 all=195122 active=13201 piece=▁딱\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1185 size=560 all=197234 active=15313 piece=▁치\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1152 size=580 all=199953 active=18032 piece=▁가족\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1128 size=600 all=202002 active=20081 piece=라도\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=1128 min_freq=53\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1080 size=620 all=204331 active=12193 piece=▁야\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1051 size=640 all=206248 active=14110 piece=▁연기가\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=1022 size=660 all=208241 active=16103 piece=▁진심\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=995 size=680 all=211052 active=18914 piece=▁메\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=965 size=700 all=212777 active=20639 piece=▁제대로\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=965 min_freq=49\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=935 size=720 all=214576 active=12404 piece=▁나름\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=906 size=740 all=216245 active=14073 piece=▁각\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=874 size=760 all=217628 active=15456 piece=▁보고싶\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=859 size=780 all=219272 active=17100 piece=▁따뜻\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=841 size=800 all=220699 active=18527 piece=▁스토리도\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=840 min_freq=46\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=819 size=820 all=222471 active=12784 piece=▁영화였\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=803 size=840 all=223714 active=14027 piece=▁도대체\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=774 size=860 all=225184 active=15497 piece=▁관객\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=764 size=880 all=226305 active=16618 piece=▁점수\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=748 size=900 all=227913 active=18226 piece=없음\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=748 min_freq=44\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=730 size=920 all=229437 active=12764 piece=▁허접\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=715 size=940 all=231037 active=14364 piece=▁뛰\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=701 size=960 all=232169 active=15496 piece=▁문제\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=687 size=980 all=233209 active=16536 piece=▁왠\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=673 size=1000 all=234364 active=17691 piece=▁유쾌\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=673 min_freq=42\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=660 size=1020 all=236036 active=13362 piece=▁지루함\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=649 size=1040 all=237638 active=14964 piece=▁기억에\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=629 size=1060 all=239227 active=16553 piece=▁보지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=616 size=1080 all=240714 active=18040 piece=▁궁금\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=601 size=1100 all=242185 active=19511 piece=자기\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=601 min_freq=41\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=588 size=1120 all=243377 active=13195 piece=▁ᄒ\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=575 size=1140 all=244605 active=14423 piece=▁나올\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=561 size=1160 all=246278 active=16096 piece=전개\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=551 size=1180 all=247410 active=17228 piece=자가\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=542 size=1200 all=248983 active=18801 piece=▁좋아요\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=540 min_freq=39\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=527 size=1220 all=250454 active=13889 piece=▁똥\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=515 size=1240 all=252085 active=15520 piece=▁S\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=506 size=1260 all=253400 active=16835 piece=▁흔\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=498 size=1280 all=254760 active=18194 piece=수준\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=486 size=1300 all=256248 active=19682 piece=▁딸\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=486 min_freq=37\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=475 size=1320 all=257764 active=14249 piece=▁등장\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=467 size=1340 all=259084 active=15569 piece=▁꼬\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=463 size=1360 all=260210 active=16695 piece=▁생각보다\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=456 size=1380 all=262079 active=18564 piece=▁b\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=449 size=1400 all=263146 active=19631 piece=졌다\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=449 min_freq=36\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=441 size=1420 all=264952 active=14896 piece=▁있을까\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=434 size=1440 all=265777 active=15721 piece=▁이영화를\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=427 size=1460 all=266860 active=16804 piece=▁제가\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=419 size=1480 all=267741 active=17685 piece=들어\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=412 size=1500 all=269115 active=19059 piece=에선\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=412 min_freq=34\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=404 size=1520 all=270597 active=14780 piece=음악\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=396 size=1540 all=271503 active=15686 piece=▁끝나\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=391 size=1560 all=272653 active=16836 piece=▁여주\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=386 size=1580 all=273735 active=17918 piece=▁판타지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=380 size=1600 all=274812 active=18995 piece=▁역대\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=380 min_freq=33\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=375 size=1620 all=275642 active=14557 piece=▁그런지\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=371 size=1640 all=276897 active=15812 piece=우드\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=365 size=1660 all=278132 active=17047 piece=▁비해\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=362 size=1680 all=279352 active=18267 piece=▁합니다\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=355 size=1700 all=280557 active=19472 piece=진진\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=354 min_freq=32\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=351 size=1720 all=282197 active=15627 piece=▁헐리\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=346 size=1740 all=283347 active=16777 piece=▁엉망\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=341 size=1760 all=284339 active=17769 piece=촬영\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=336 size=1780 all=285567 active=18997 piece=▁전개가\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=331 size=1800 all=286438 active=19868 piece=▁겨\n",
      "bpe_model_trainer.cc(167) LOG(INFO) Updating active symbols. max_freq=331 min_freq=31\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=329 size=1820 all=287567 active=15436 piece=▁한마디로\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=323 size=1840 all=288704 active=16573 piece=▁창\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=320 size=1860 all=290283 active=18152 piece=▁액션도\n",
      "bpe_model_trainer.cc(258) LOG(INFO) Added: freq=316 size=1880 all=291172 active=19041 piec"
     ]
    }
   ],
   "source": [
    "temp_file = os.getenv('HOME') + '/aiffel/sp_tokenizer/data/nsmc/ratings.txt.temp'\n",
    "\n",
    "vocab_size = 8000\n",
    "\n",
    "with open(temp_file, 'w') as f:\n",
    "    for row in filtered_data['document']:   # 이전 스텝에서 정제했던 corpus를 활용합니다.\n",
    "        f.write(str(row) + '\\n')\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=kor_spm_unigram_8k --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "\n",
    "spm.SentencePieceTrainer.Train(\n",
    "    '--input={} --model_prefix=kor_spm_bep_8k --model_type=bpe --vocab_size={}'.format(temp_file, vocab_size)    \n",
    ")\n",
    "\n",
    "#위 Train에서  --model_type = 'unigram'이 디폴트 적용되어 있습니다. --model_type = 'bpe' 로 옵션을 주어 변경할 수 있습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "69d99b62",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-rw-r--r-- 1 root root 374860 Jul 11 00:24 kor_spm_unigram_8k.model\n",
      "-rw-r--r-- 1 root root 144321 Jul 11 00:24 kor_spm_unigram_8k.vocab\n",
      "-rw-r--r-- 1 root root 370341 Jul 11 00:25 kor_spm_bep_8k.model\n",
      "-rw-r--r-- 1 root root 115555 Jul 11 00:25 kor_spm_bep_8k.vocab\n"
     ]
    }
   ],
   "source": [
    "!ls -l kor_spm_unigram_8k*\n",
    "!ls -l kor_spm_bep_8k*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a95585d7",
   "metadata": {},
   "source": [
    "## Comparing vocab between unigram and bpe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "863957b7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>0.00000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>▁</td>\n",
       "      <td>-3.32209</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>.</td>\n",
       "      <td>-3.48143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>..</td>\n",
       "      <td>-4.39524</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>이</td>\n",
       "      <td>-4.40150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>▁영화</td>\n",
       "      <td>-4.58411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>-4.63875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>의</td>\n",
       "      <td>-4.71148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0        1\n",
       "0  <unk>  0.00000\n",
       "1    <s>  0.00000\n",
       "2   </s>  0.00000\n",
       "3      ▁ -3.32209\n",
       "4      . -3.48143\n",
       "5     .. -4.39524\n",
       "6      이 -4.40150\n",
       "7    ▁영화 -4.58411\n",
       "8    ... -4.63875\n",
       "9      의 -4.71148"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_vocab_list = pd.read_csv('kor_spm_unigram_8k.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "unigram_vocab_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e3f8ab83",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2831</th>\n",
       "      <td>▁안됨</td>\n",
       "      <td>-9.70546</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>거라</td>\n",
       "      <td>-9.63074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>702</th>\n",
       "      <td>▁초</td>\n",
       "      <td>-8.37019</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4168</th>\n",
       "      <td>▁감히</td>\n",
       "      <td>-10.12360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3249</th>\n",
       "      <td>▁퇴</td>\n",
       "      <td>-9.85060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3178</th>\n",
       "      <td>자리</td>\n",
       "      <td>-9.82907</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3915</th>\n",
       "      <td>만큼은</td>\n",
       "      <td>-10.04850</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>269</th>\n",
       "      <td>▁일</td>\n",
       "      <td>-7.61519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2528</th>\n",
       "      <td>에서도</td>\n",
       "      <td>-9.60267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4646</th>\n",
       "      <td>▁변화</td>\n",
       "      <td>-10.25990</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        0         1\n",
       "2831  ▁안됨  -9.70546\n",
       "2619   거라  -9.63074\n",
       "702    ▁초  -8.37019\n",
       "4168  ▁감히 -10.12360\n",
       "3249   ▁퇴  -9.85060\n",
       "3178   자리  -9.82907\n",
       "3915  만큼은 -10.04850\n",
       "269    ▁일  -7.61519\n",
       "2528  에서도  -9.60267\n",
       "4646  ▁변화 -10.25990"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unigram_vocab_list.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "004deab5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>&lt;unk&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>&lt;s&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>&lt;/s&gt;</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>..</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>영화</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>▁영화</td>\n",
       "      <td>-2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>▁이</td>\n",
       "      <td>-3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>▁아</td>\n",
       "      <td>-4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>...</td>\n",
       "      <td>-5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>▁그</td>\n",
       "      <td>-6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       0  1\n",
       "0  <unk>  0\n",
       "1    <s>  0\n",
       "2   </s>  0\n",
       "3     ..  0\n",
       "4     영화 -1\n",
       "5    ▁영화 -2\n",
       "6     ▁이 -3\n",
       "7     ▁아 -4\n",
       "8    ... -5\n",
       "9     ▁그 -6"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_vocab_list = pd.read_csv('kor_spm_bep_8k.vocab', sep='\\t', header=None, quoting=csv.QUOTE_NONE)\n",
    "bpe_vocab_list[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "9fff1b81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6199</th>\n",
       "      <td>▁홍상수</td>\n",
       "      <td>-6196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5960</th>\n",
       "      <td>보구</td>\n",
       "      <td>-5957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5218</th>\n",
       "      <td>▁줘야</td>\n",
       "      <td>-5215</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2968</th>\n",
       "      <td>▁지구</td>\n",
       "      <td>-2965</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1004</th>\n",
       "      <td>▁암</td>\n",
       "      <td>-1001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5529</th>\n",
       "      <td>▁이제는</td>\n",
       "      <td>-5526</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7791</th>\n",
       "      <td>갚</td>\n",
       "      <td>-7788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1074</th>\n",
       "      <td>▁브</td>\n",
       "      <td>-1071</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>▁살</td>\n",
       "      <td>-191</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4360</th>\n",
       "      <td>부를</td>\n",
       "      <td>-4357</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         0     1\n",
       "6199  ▁홍상수 -6196\n",
       "5960    보구 -5957\n",
       "5218   ▁줘야 -5215\n",
       "2968   ▁지구 -2965\n",
       "1004    ▁암 -1001\n",
       "5529  ▁이제는 -5526\n",
       "7791     갚 -7788\n",
       "1074    ▁브 -1071\n",
       "194     ▁살  -191\n",
       "4360    부를 -4357"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bpe_vocab_list.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c3d732ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_performance(model):\n",
    "    s = spm.SentencePieceProcessor()\n",
    "    s.Load(model)\n",
    "\n",
    "    # SentencePiece를 활용한 sentence -> encoding\n",
    "    tokensIDs = s.EncodeAsIds('아버지가방에들어가신다.')\n",
    "    print(tokensIDs)\n",
    "\n",
    "    # SentencePiece를 활용한 sentence -> encoded pieces\n",
    "    print(s.SampleEncodeAsPieces('아버지가방에들어가신다.',1, 0.0))\n",
    "\n",
    "    # SentencePiece를 활용한 encoding -> sentence 복원\n",
    "    print(s.DecodeIds(tokensIDs))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c537b2",
   "metadata": {},
   "source": [
    "unigram이 좀더 정확하게 tokeninzing 하는 걸 확인"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b85f4688",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kor_spm_unigram_8k\n",
      "[1390, 10, 382, 15, 1303, 10, 129, 18, 4]\n",
      "['▁아버지', '가', '방', '에', '들어', '가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n",
      "kor_spm_bep_8k\n",
      "[4803, 869, 6549, 6298, 6317, 1370, 6395, 6288, 6286]\n",
      "['▁아버', '지가', '방', '에', '들', '어가', '신', '다', '.']\n",
      "아버지가방에들어가신다.\n"
     ]
    }
   ],
   "source": [
    "print('kor_spm_unigram_8k')\n",
    "test_performance(model='kor_spm_unigram_8k.model')\n",
    "\n",
    "print('kor_spm_bep_8k')\n",
    "test_performance(model='kor_spm_bep_8k.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "17742c6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sp_tokenize(s, corpus, path):\n",
    "\n",
    "    tensor = []\n",
    "\n",
    "    for sen in corpus:\n",
    "        tensor.append(s.EncodeAsIds(sen))\n",
    "\n",
    "    with open(path, 'r') as f:\n",
    "        vocab = f.readlines()\n",
    "\n",
    "    word_index = {}\n",
    "    index_word = {}\n",
    "\n",
    "    for idx, line in enumerate(vocab):\n",
    "        word = line.split(\"\\t\")[0]\n",
    "\n",
    "        word_index.update({idx:word})\n",
    "        index_word.update({word:idx})\n",
    "\n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "\n",
    "    return tensor, word_index, index_word"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5fcea924",
   "metadata": {},
   "source": [
    "## BPE + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3953a08b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1744  161  227 ...    0    0    0]\n",
      " [ 740 6342 2188 ...    0    0    0]\n",
      " [3131  685  636 ...    0    0    0]\n",
      " ...\n",
      " [ 216 5321    4 ...    0    0    0]\n",
      " [  84 6433  157 ...    0    0    0]\n",
      " [ 339 6851 6424 ...    0    0    0]]\n"
     ]
    }
   ],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('kor_spm_bep_8k.model')\n",
    "\n",
    "tensor, word_index, index_word = sp_tokenize(s, filtered_data['document'], \"./kor_spm_bep_8k.vocab\")\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "15813ab3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(181695, 131)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f14c1a5c",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "669297a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 8000\n",
    "word_vector_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f961cfe0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_label = np.array(filtered_data['label'])\n",
    "x_train, x_val, y_train, y_val = train_test_split(tensor, filtered_label, test_size=0.2)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1fdf614f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding (Embedding)        (None, None, 128)         1024000   \n",
      "_________________________________________________________________\n",
      "lstm (LSTM)                  (None, None, 128)         131584    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, None, 1)           129       \n",
      "=================================================================\n",
      "Total params: 1,155,713\n",
      "Trainable params: 1,155,713\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(128, return_sequences = True))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b40b6c00",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b0ac5501",
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "check = ModelCheckpoint('bpe_best_model_lstm.h5', monitor='val_acc', mode='max', verbose=1, save_bast_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "705975df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1274/1817 [====================>.........] - ETA: 3:55 - loss: 0.5721 - accuracy: 0.7182"
     ]
    }
   ],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "lstm_history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data = (x_val,y_val),\n",
    "                    callbacks = [early,check],\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f79fea79",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae983e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train(train_history, param):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(train_history.history['accuracy'])\n",
    "    plt.plot(train_history.history['val_accuracy'])\n",
    "    plt.title('{}_accuracy'.format(param))\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(train_history.history['loss'])\n",
    "    plt.plot(train_history.history['val_loss'])\n",
    "    plt.title('{}_loss'.format(param))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b90b179",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_train(lstm_history, param = 'bpe_8k_dim_128')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3734f6ac",
   "metadata": {},
   "source": [
    "## Unigram + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac5d69cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "s = spm.SentencePieceProcessor()\n",
    "s.Load('kor_spm_unigram_8k.model.model')\n",
    "\n",
    "tensor, word_index, index_word = sp_tokenize(s, filtered_data['document'], \"./kor_spm_unigram_8k.vocab\")\n",
    "print(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35ce574c",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f45d3aeb",
   "metadata": {},
   "source": [
    "## Traning and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ec645dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 8000\n",
    "word_vector_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d5e0e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_label = np.array(filtered_data['label'])\n",
    "x_train, x_val, y_train, y_val = train_test_split(tensor, filtered_label, test_size=0.2)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d56d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(128, return_sequences = True))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3675fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c9b45da",
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "check = ModelCheckpoint('unigram_best_model_lstm.h5', monitor='val_acc', mode='max', verbose=1, save_bast_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f866f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "lstm_history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data = (x_val,y_val),\n",
    "                    callbacks = [early,check],\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b55192b",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae183860",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train(train_history, param):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(train_history.history['accuracy'])\n",
    "    plt.plot(train_history.history['val_accuracy'])\n",
    "    plt.title('{}_accuracy'.format(param))\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(train_history.history['loss'])\n",
    "    plt.plot(train_history.history['val_loss'])\n",
    "    plt.title('{}_loss'.format(param))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ffa430",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "visualize_train(lstm_history, param = 'unigram_8k_dim_128')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8719fd5",
   "metadata": {},
   "source": [
    "## Mecab + LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8265b33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab = Mecab()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8c2b047",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mecab_split(sentence):\n",
    "    return mecab.morphs(sentence)\n",
    "\n",
    "mecab_corpus = []\n",
    "\n",
    "for kor in filtered_data['document']:\n",
    "    mecab_corpus.append(mecab_split(kor))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88896d1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(corpus):  # corpus: Tokenized Sentence's List\n",
    "    tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='')\n",
    "    tokenizer.fit_on_texts(corpus)\n",
    "    '''\n",
    "    위의 tokenizer 코드\n",
    "    : corpus를 쪼개서 단어사전을 만듬\n",
    "    '''\n",
    "\n",
    "    tensor = tokenizer.texts_to_sequences(corpus)\n",
    "    \n",
    "    tensor = tf.keras.preprocessing.sequence.pad_sequences(tensor, padding='post')\n",
    "    '''\n",
    "    위의 tensor 코드\n",
    "    : corpus에 담긴 각 문장들을 단어사전으로 표현함\n",
    "    '''\n",
    "    return tensor, tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51e766f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_tensor, mecab_tokenizer = tokenize(mecab_corpus)\n",
    "\n",
    "print(\"MeCab Vocab Size:\", len(mecab_tokenizer.index_word))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbb1de3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "mecab_tensor.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dd3f209",
   "metadata": {},
   "source": [
    "## Traning and Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be5c165",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 60326 + 1\n",
    "word_vector_dim = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1872e08",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_label = np.array(filtered_data['label'])\n",
    "\n",
    "x_train, x_val, y_train, y_val = train_test_split(mecab_tensor, filtered_label, test_size=0.2)\n",
    "x_train, x_test, y_train, y_test = train_test_split(x_train, y_train, test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a440ec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(tf.keras.layers.Embedding(vocab_size, word_vector_dim, input_shape=(None,)))\n",
    "model.add(tf.keras.layers.LSTM(128, return_sequences = True))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c34da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db0b0a34",
   "metadata": {},
   "outputs": [],
   "source": [
    "early = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=5)\n",
    "check = ModelCheckpoint('mecab_best_model_lstm.h5', monitor='val_acc', mode='max', verbose=1, save_bast_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4935cab8",
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs = 5\n",
    "batch_size = 64\n",
    "\n",
    "lstm_history = model.fit(x_train,\n",
    "                    y_train,\n",
    "                    epochs = epochs,\n",
    "                    batch_size = batch_size,\n",
    "                    validation_data = (x_val,y_val),\n",
    "                    callbacks = [early,check],\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55029c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.evaluate(x_test,  y_test, verbose=2)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70b82f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_train(train_history, param):\n",
    "    # summarize history for accuracy\n",
    "    plt.plot(train_history.history['accuracy'])\n",
    "    plt.plot(train_history.history['val_accuracy'])\n",
    "    plt.title('{}_accuracy'.format(param))\n",
    "    plt.ylabel('accuracy')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()\n",
    "    # summarize history for loss\n",
    "    plt.plot(train_history.history['loss'])\n",
    "    plt.plot(train_history.history['val_loss'])\n",
    "    plt.title('{}_loss'.format(param))\n",
    "    plt.ylabel('loss')\n",
    "    plt.xlabel('epoch')\n",
    "    plt.legend(['train', 'val'], loc='upper left')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db8ddb7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_train(lstm_history, param = 'mecab_dim_128')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5059f0e0",
   "metadata": {},
   "source": [
    "## Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad695ed",
   "metadata": {},
   "source": [
    "1. SentencePiece를 이용하여 모델을 만들기까지의 과정이 정상적으로 진행되었는가?  \n",
    " - 코퍼스 분석, 전처리, SentencePiece 적용, 토크나이저 구현 및 동작이 빠짐없이 진행되었는가?  \n",
    "2. SentencePiece를 통해 만든 Tokenizer가 자연어처리 모델과 결합하여 동작하는가?  \n",
    " - SentencePiece 토크나이저가 적용된 Text Classifier 모델이 정상적으로 수렴하여 80% 이상의 test accuracy가 확인되었다.  \n",
    "3. SentencePiece의 성능을 다각도로 비교분석하였는가?  \n",
    " - SentencePiece 토크나이저를 활용했을 때의 성능을 다른 토크나이저 혹은 SentencePiece의 다른 옵션의 경우와 비교하여 분석을 체계적으로 진행하였다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0858e948",
   "metadata": {},
   "source": [
    "## Reference"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f85a019",
   "metadata": {},
   "source": [
    "1. https://github.com/miinkang/AI_Project_AIFFEL/blob/main/%5BGD-02%5DSentencePiece.ipynb"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
