{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4c6c39e7",
   "metadata": {},
   "source": [
    "# 프로젝트 설명"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5da6b2e",
   "metadata": {},
   "source": [
    "본 프로젝트는 python의 scikit-learn 라이브러리에서 제공하는 세 가지의 toy dataset을 사용하여, 다섯 가지 분류 모델에 적용하여 어떤 모델이 좋은 성능을 보이는지 확인하고자 한다. 또한, 예측 결과를 어떻게 해석하고, 모델의 성능을 평가하는 지표로는 어떤 것을 선택할지에 대해 생각해보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6ae837",
   "metadata": {},
   "source": [
    "### 패키지 임포트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 564,
   "id": "9d358ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data collection\n",
    "from sklearn.datasets import load_digits, load_wine, load_breast_cancer\n",
    "\n",
    "# Data preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Model\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "\n",
    "\n",
    "# Performace index\n",
    "from sklearn.metrics import precision_score, recall_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "214780c2",
   "metadata": {},
   "source": [
    "### 데이터 준비(Data collection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 565,
   "id": "50e2ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "digits = load_digits()\n",
    "wine = load_wine()\n",
    "bcan = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc452a1a",
   "metadata": {},
   "source": [
    "### 데이터 살펴보기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "aad4e8fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def toydata_eda(data):\n",
    "    \n",
    "    # EDA\n",
    "    data_structure = {}\n",
    "    data_name = data.DESCR.split('\\n')[0].split(\"_\")[1]\n",
    "    \n",
    "    print(f\" Summary of {data_name} dataset\", end = '\\n\\n\\n')\n",
    "    print(f\" Keys of {data_name} datasets : {data.keys()}\")\n",
    "    print(\"-------------------------------------------------------------------------------\", end = \"\\n\\n\")\n",
    "    print(f\" Shape of {data_name} datasets : {data.data.shape}\")\n",
    "    print(\"-------------------------------------------------------------------------------\", end = \"\\n\\n\")\n",
    "    print(f\" Target name of {data_name} datasets : {data.target_names}\")\n",
    "    print(\"-------------------------------------------------------------------------------\", end = \"\\n\\n\")\n",
    "    print(f\" Description of {data_name} datasets : \\n {data.DESCR}\")\n",
    "    print(\"-------------------------------------------------------------------------------\", end = \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 659,
   "id": "aa458a56",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Summary of digits dataset\n",
      "\n",
      "\n",
      " Keys of digits datasets : dict_keys(['data', 'target', 'frame', 'feature_names', 'target_names', 'images', 'DESCR'])\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " Shape of digits datasets : (1797, 64)\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " Target name of digits datasets : [0 1 2 3 4 5 6 7 8 9]\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " Description of digits datasets : \n",
      " .. _digits_dataset:\n",
      "\n",
      "Optical recognition of handwritten digits dataset\n",
      "--------------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 1797\n",
      "    :Number of Attributes: 64\n",
      "    :Attribute Information: 8x8 image of integer pixels in the range 0..16.\n",
      "    :Missing Attribute Values: None\n",
      "    :Creator: E. Alpaydin (alpaydin '@' boun.edu.tr)\n",
      "    :Date: July; 1998\n",
      "\n",
      "This is a copy of the test set of the UCI ML hand-written digits datasets\n",
      "https://archive.ics.uci.edu/ml/datasets/Optical+Recognition+of+Handwritten+Digits\n",
      "\n",
      "The data set contains images of hand-written digits: 10 classes where\n",
      "each class refers to a digit.\n",
      "\n",
      "Preprocessing programs made available by NIST were used to extract\n",
      "normalized bitmaps of handwritten digits from a preprinted form. From a\n",
      "total of 43 people, 30 contributed to the training set and different 13\n",
      "to the test set. 32x32 bitmaps are divided into nonoverlapping blocks of\n",
      "4x4 and the number of on pixels are counted in each block. This generates\n",
      "an input matrix of 8x8 where each element is an integer in the range\n",
      "0..16. This reduces dimensionality and gives invariance to small\n",
      "distortions.\n",
      "\n",
      "For info on NIST preprocessing routines, see M. D. Garris, J. L. Blue, G.\n",
      "T. Candela, D. L. Dimmick, J. Geist, P. J. Grother, S. A. Janet, and C.\n",
      "L. Wilson, NIST Form-Based Handprint Recognition System, NISTIR 5469,\n",
      "1994.\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  - C. Kaynak (1995) Methods of Combining Multiple Classifiers and Their\n",
      "    Applications to Handwritten Digit Recognition, MSc Thesis, Institute of\n",
      "    Graduate Studies in Science and Engineering, Bogazici University.\n",
      "  - E. Alpaydin, C. Kaynak (1998) Cascading Classifiers, Kybernetika.\n",
      "  - Ken Tang and Ponnuthurai N. Suganthan and Xi Yao and A. Kai Qin.\n",
      "    Linear dimensionalityreduction using relevance weighted LDA. School of\n",
      "    Electrical and Electronic Engineering Nanyang Technological University.\n",
      "    2005.\n",
      "  - Claudio Gentile. A New Approximate Maximal Margin Classification\n",
      "    Algorithm. NIPS. 2000.\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>54</th>\n",
       "      <th>55</th>\n",
       "      <th>56</th>\n",
       "      <th>57</th>\n",
       "      <th>58</th>\n",
       "      <th>59</th>\n",
       "      <th>60</th>\n",
       "      <th>61</th>\n",
       "      <th>62</th>\n",
       "      <th>63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>1797.0</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "      <td>1797.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.303840</td>\n",
       "      <td>5.204786</td>\n",
       "      <td>11.835838</td>\n",
       "      <td>11.848080</td>\n",
       "      <td>5.781859</td>\n",
       "      <td>1.362270</td>\n",
       "      <td>0.129661</td>\n",
       "      <td>0.005565</td>\n",
       "      <td>1.993879</td>\n",
       "      <td>...</td>\n",
       "      <td>3.725097</td>\n",
       "      <td>0.206455</td>\n",
       "      <td>0.000556</td>\n",
       "      <td>0.279354</td>\n",
       "      <td>5.557596</td>\n",
       "      <td>12.089037</td>\n",
       "      <td>11.809126</td>\n",
       "      <td>6.764051</td>\n",
       "      <td>2.067891</td>\n",
       "      <td>0.364496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.907192</td>\n",
       "      <td>4.754826</td>\n",
       "      <td>4.248842</td>\n",
       "      <td>4.287388</td>\n",
       "      <td>5.666418</td>\n",
       "      <td>3.325775</td>\n",
       "      <td>1.037383</td>\n",
       "      <td>0.094222</td>\n",
       "      <td>3.196160</td>\n",
       "      <td>...</td>\n",
       "      <td>4.919406</td>\n",
       "      <td>0.984401</td>\n",
       "      <td>0.023590</td>\n",
       "      <td>0.934302</td>\n",
       "      <td>5.103019</td>\n",
       "      <td>4.374694</td>\n",
       "      <td>4.933947</td>\n",
       "      <td>5.900623</td>\n",
       "      <td>4.090548</td>\n",
       "      <td>1.860122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>6.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>12.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>0.0</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "      <td>16.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           0            1            2            3            4   \\\n",
       "count  1797.0  1797.000000  1797.000000  1797.000000  1797.000000   \n",
       "mean      0.0     0.303840     5.204786    11.835838    11.848080   \n",
       "std       0.0     0.907192     4.754826     4.248842     4.287388   \n",
       "min       0.0     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.0     0.000000     1.000000    10.000000    10.000000   \n",
       "50%       0.0     0.000000     4.000000    13.000000    13.000000   \n",
       "75%       0.0     0.000000     9.000000    15.000000    15.000000   \n",
       "max       0.0     8.000000    16.000000    16.000000    16.000000   \n",
       "\n",
       "                5            6            7            8            9   ...  \\\n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  ...   \n",
       "mean      5.781859     1.362270     0.129661     0.005565     1.993879  ...   \n",
       "std       5.666418     3.325775     1.037383     0.094222     3.196160  ...   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "50%       4.000000     0.000000     0.000000     0.000000     0.000000  ...   \n",
       "75%      11.000000     0.000000     0.000000     0.000000     3.000000  ...   \n",
       "max      16.000000    16.000000    15.000000     2.000000    16.000000  ...   \n",
       "\n",
       "                54           55           56           57           58  \\\n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000   \n",
       "mean      3.725097     0.206455     0.000556     0.279354     5.557596   \n",
       "std       4.919406     0.984401     0.023590     0.934302     5.103019   \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
       "25%       0.000000     0.000000     0.000000     0.000000     1.000000   \n",
       "50%       1.000000     0.000000     0.000000     0.000000     4.000000   \n",
       "75%       7.000000     0.000000     0.000000     0.000000    10.000000   \n",
       "max      16.000000    13.000000     1.000000     9.000000    16.000000   \n",
       "\n",
       "                59           60           61           62           63  \n",
       "count  1797.000000  1797.000000  1797.000000  1797.000000  1797.000000  \n",
       "mean     12.089037    11.809126     6.764051     2.067891     0.364496  \n",
       "std       4.374694     4.933947     5.900623     4.090548     1.860122  \n",
       "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
       "25%      11.000000    10.000000     0.000000     0.000000     0.000000  \n",
       "50%      13.000000    14.000000     6.000000     0.000000     0.000000  \n",
       "75%      16.000000    16.000000    12.000000     2.000000     0.000000  \n",
       "max      16.000000    16.000000    16.000000    16.000000    16.000000  \n",
       "\n",
       "[8 rows x 64 columns]"
      ]
     },
     "execution_count": 659,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toydata_eda(digits)\n",
    "import pandas as pd\n",
    "\n",
    "pd.DataFrame(digits.data).describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 654,
   "id": "a75f094b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Summary of wine dataset\n",
      "\n",
      "\n",
      " Keys of wine datasets : dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names'])\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " Shape of wine datasets : (178, 13)\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " Target name of wine datasets : ['class_0' 'class_1' 'class_2']\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " Description of wine datasets : \n",
      " .. _wine_dataset:\n",
      "\n",
      "Wine recognition dataset\n",
      "------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 178 (50 in each of three classes)\n",
      "    :Number of Attributes: 13 numeric, predictive attributes and the class\n",
      "    :Attribute Information:\n",
      " \t\t- Alcohol\n",
      " \t\t- Malic acid\n",
      " \t\t- Ash\n",
      "\t\t- Alcalinity of ash  \n",
      " \t\t- Magnesium\n",
      "\t\t- Total phenols\n",
      " \t\t- Flavanoids\n",
      " \t\t- Nonflavanoid phenols\n",
      " \t\t- Proanthocyanins\n",
      "\t\t- Color intensity\n",
      " \t\t- Hue\n",
      " \t\t- OD280/OD315 of diluted wines\n",
      " \t\t- Proline\n",
      "\n",
      "    - class:\n",
      "            - class_0\n",
      "            - class_1\n",
      "            - class_2\n",
      "\t\t\n",
      "    :Summary Statistics:\n",
      "    \n",
      "    ============================= ==== ===== ======= =====\n",
      "                                   Min   Max   Mean     SD\n",
      "    ============================= ==== ===== ======= =====\n",
      "    Alcohol:                      11.0  14.8    13.0   0.8\n",
      "    Malic Acid:                   0.74  5.80    2.34  1.12\n",
      "    Ash:                          1.36  3.23    2.36  0.27\n",
      "    Alcalinity of Ash:            10.6  30.0    19.5   3.3\n",
      "    Magnesium:                    70.0 162.0    99.7  14.3\n",
      "    Total Phenols:                0.98  3.88    2.29  0.63\n",
      "    Flavanoids:                   0.34  5.08    2.03  1.00\n",
      "    Nonflavanoid Phenols:         0.13  0.66    0.36  0.12\n",
      "    Proanthocyanins:              0.41  3.58    1.59  0.57\n",
      "    Colour Intensity:              1.3  13.0     5.1   2.3\n",
      "    Hue:                          0.48  1.71    0.96  0.23\n",
      "    OD280/OD315 of diluted wines: 1.27  4.00    2.61  0.71\n",
      "    Proline:                       278  1680     746   315\n",
      "    ============================= ==== ===== ======= =====\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "    :Class Distribution: class_0 (59), class_1 (71), class_2 (48)\n",
      "    :Creator: R.A. Fisher\n",
      "    :Donor: Michael Marshall (MARSHALL%PLU@io.arc.nasa.gov)\n",
      "    :Date: July, 1988\n",
      "\n",
      "This is a copy of UCI ML Wine recognition datasets.\n",
      "https://archive.ics.uci.edu/ml/machine-learning-databases/wine/wine.data\n",
      "\n",
      "The data is the results of a chemical analysis of wines grown in the same\n",
      "region in Italy by three different cultivators. There are thirteen different\n",
      "measurements taken for different constituents found in the three types of\n",
      "wine.\n",
      "\n",
      "Original Owners: \n",
      "\n",
      "Forina, M. et al, PARVUS - \n",
      "An Extendible Package for Data Exploration, Classification and Correlation. \n",
      "Institute of Pharmaceutical and Food Analysis and Technologies,\n",
      "Via Brigata Salerno, 16147 Genoa, Italy.\n",
      "\n",
      "Citation:\n",
      "\n",
      "Lichman, M. (2013). UCI Machine Learning Repository\n",
      "[https://archive.ics.uci.edu/ml]. Irvine, CA: University of California,\n",
      "School of Information and Computer Science. \n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "  (1) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  Comparison of Classifiers in High Dimensional Settings, \n",
      "  Tech. Rep. no. 92-02, (1992), Dept. of Computer Science and Dept. of  \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Technometrics). \n",
      "\n",
      "  The data was used with many others for comparing various \n",
      "  classifiers. The classes are separable, though only RDA \n",
      "  has achieved 100% correct classification. \n",
      "  (RDA : 100%, QDA 99.4%, LDA 98.9%, 1NN 96.1% (z-transformed data)) \n",
      "  (All results using the leave-one-out technique) \n",
      "\n",
      "  (2) S. Aeberhard, D. Coomans and O. de Vel, \n",
      "  \"THE CLASSIFICATION PERFORMANCE OF RDA\" \n",
      "  Tech. Rep. no. 92-01, (1992), Dept. of Computer Science and Dept. of \n",
      "  Mathematics and Statistics, James Cook University of North Queensland. \n",
      "  (Also submitted to Journal of Chemometrics).\n",
      "\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toydata_eda(wine)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "715fad0b",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Summary of breast dataset\n",
      "\n",
      "\n",
      " Keys of breast datasets : dict_keys(['data', 'target', 'frame', 'target_names', 'DESCR', 'feature_names', 'filename', 'data_module'])\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " Shape of breast datasets : (569, 30)\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " Target name of breast datasets : ['malignant' 'benign']\n",
      "-------------------------------------------------------------------------------\n",
      "\n",
      " Description of breast datasets : \n",
      " .. _breast_cancer_dataset:\n",
      "\n",
      "Breast cancer wisconsin (diagnostic) dataset\n",
      "--------------------------------------------\n",
      "\n",
      "**Data Set Characteristics:**\n",
      "\n",
      "    :Number of Instances: 569\n",
      "\n",
      "    :Number of Attributes: 30 numeric, predictive attributes and the class\n",
      "\n",
      "    :Attribute Information:\n",
      "        - radius (mean of distances from center to points on the perimeter)\n",
      "        - texture (standard deviation of gray-scale values)\n",
      "        - perimeter\n",
      "        - area\n",
      "        - smoothness (local variation in radius lengths)\n",
      "        - compactness (perimeter^2 / area - 1.0)\n",
      "        - concavity (severity of concave portions of the contour)\n",
      "        - concave points (number of concave portions of the contour)\n",
      "        - symmetry\n",
      "        - fractal dimension (\"coastline approximation\" - 1)\n",
      "\n",
      "        The mean, standard error, and \"worst\" or largest (mean of the three\n",
      "        worst/largest values) of these features were computed for each image,\n",
      "        resulting in 30 features.  For instance, field 0 is Mean Radius, field\n",
      "        10 is Radius SE, field 20 is Worst Radius.\n",
      "\n",
      "        - class:\n",
      "                - WDBC-Malignant\n",
      "                - WDBC-Benign\n",
      "\n",
      "    :Summary Statistics:\n",
      "\n",
      "    ===================================== ====== ======\n",
      "                                           Min    Max\n",
      "    ===================================== ====== ======\n",
      "    radius (mean):                        6.981  28.11\n",
      "    texture (mean):                       9.71   39.28\n",
      "    perimeter (mean):                     43.79  188.5\n",
      "    area (mean):                          143.5  2501.0\n",
      "    smoothness (mean):                    0.053  0.163\n",
      "    compactness (mean):                   0.019  0.345\n",
      "    concavity (mean):                     0.0    0.427\n",
      "    concave points (mean):                0.0    0.201\n",
      "    symmetry (mean):                      0.106  0.304\n",
      "    fractal dimension (mean):             0.05   0.097\n",
      "    radius (standard error):              0.112  2.873\n",
      "    texture (standard error):             0.36   4.885\n",
      "    perimeter (standard error):           0.757  21.98\n",
      "    area (standard error):                6.802  542.2\n",
      "    smoothness (standard error):          0.002  0.031\n",
      "    compactness (standard error):         0.002  0.135\n",
      "    concavity (standard error):           0.0    0.396\n",
      "    concave points (standard error):      0.0    0.053\n",
      "    symmetry (standard error):            0.008  0.079\n",
      "    fractal dimension (standard error):   0.001  0.03\n",
      "    radius (worst):                       7.93   36.04\n",
      "    texture (worst):                      12.02  49.54\n",
      "    perimeter (worst):                    50.41  251.2\n",
      "    area (worst):                         185.2  4254.0\n",
      "    smoothness (worst):                   0.071  0.223\n",
      "    compactness (worst):                  0.027  1.058\n",
      "    concavity (worst):                    0.0    1.252\n",
      "    concave points (worst):               0.0    0.291\n",
      "    symmetry (worst):                     0.156  0.664\n",
      "    fractal dimension (worst):            0.055  0.208\n",
      "    ===================================== ====== ======\n",
      "\n",
      "    :Missing Attribute Values: None\n",
      "\n",
      "    :Class Distribution: 212 - Malignant, 357 - Benign\n",
      "\n",
      "    :Creator:  Dr. William H. Wolberg, W. Nick Street, Olvi L. Mangasarian\n",
      "\n",
      "    :Donor: Nick Street\n",
      "\n",
      "    :Date: November, 1995\n",
      "\n",
      "This is a copy of UCI ML Breast Cancer Wisconsin (Diagnostic) datasets.\n",
      "https://goo.gl/U2Uwz2\n",
      "\n",
      "Features are computed from a digitized image of a fine needle\n",
      "aspirate (FNA) of a breast mass.  They describe\n",
      "characteristics of the cell nuclei present in the image.\n",
      "\n",
      "Separating plane described above was obtained using\n",
      "Multisurface Method-Tree (MSM-T) [K. P. Bennett, \"Decision Tree\n",
      "Construction Via Linear Programming.\" Proceedings of the 4th\n",
      "Midwest Artificial Intelligence and Cognitive Science Society,\n",
      "pp. 97-101, 1992], a classification method which uses linear\n",
      "programming to construct a decision tree.  Relevant features\n",
      "were selected using an exhaustive search in the space of 1-4\n",
      "features and 1-3 separating planes.\n",
      "\n",
      "The actual linear program used to obtain the separating plane\n",
      "in the 3-dimensional space is that described in:\n",
      "[K. P. Bennett and O. L. Mangasarian: \"Robust Linear\n",
      "Programming Discrimination of Two Linearly Inseparable Sets\",\n",
      "Optimization Methods and Software 1, 1992, 23-34].\n",
      "\n",
      "This database is also available through the UW CS ftp server:\n",
      "\n",
      "ftp ftp.cs.wisc.edu\n",
      "cd math-prog/cpo-dataset/machine-learn/WDBC/\n",
      "\n",
      ".. topic:: References\n",
      "\n",
      "   - W.N. Street, W.H. Wolberg and O.L. Mangasarian. Nuclear feature extraction \n",
      "     for breast tumor diagnosis. IS&T/SPIE 1993 International Symposium on \n",
      "     Electronic Imaging: Science and Technology, volume 1905, pages 861-870,\n",
      "     San Jose, CA, 1993.\n",
      "   - O.L. Mangasarian, W.N. Street and W.H. Wolberg. Breast cancer diagnosis and \n",
      "     prognosis via linear programming. Operations Research, 43(4), pages 570-577, \n",
      "     July-August 1995.\n",
      "   - W.H. Wolberg, W.N. Street, and O.L. Mangasarian. Machine learning techniques\n",
      "     to diagnose breast cancer from fine-needle aspirates. Cancer Letters 77 (1994) \n",
      "     163-171.\n",
      "-------------------------------------------------------------------------------\n",
      "\n"
     ]
    }
   ],
   "source": [
    "toydata_eda(bcan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6b9fbdd",
   "metadata": {},
   "source": [
    "#### 데이터 별로 다양한 모델로 학습시켜보기"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c7ac50",
   "metadata": {},
   "source": [
    "#### 와인데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 627,
   "id": "4a5dad3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_classification_model(data, max_iter = 10000):\n",
    "    \n",
    "    # EDA\n",
    "    #toydata_eda(data)\n",
    "    \n",
    "    '''토이 데이터에서 feature와 그에 대한 클래스를 저장하고, 데이터셋의 이름을 저장'''\n",
    "    feature_data = data.data\n",
    "    label_data = data.target\n",
    "    name = wine.DESCR.split('\\n')[0][4:-1]\n",
    "        \n",
    "    # 훈련 데이터, 테스트 데이터 분리\n",
    "    '''훈련 데이터와 테스트 데이터로 나눌 때 비율은 초기값을 사용'''\n",
    "    train_input, test_input, train_target, test_target = train_test_split(feature_data, label_data, random_state = 24)\n",
    "    \n",
    "    # 정규화\n",
    "    '''feature 별로 숫자의 척도가 달라, 스케일링, 정규화'''\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "    \n",
    "    # 모델 셋팅\n",
    "    '''과대적합, 과소적합이 일어나지 않도록 규제에 대한 파라미터를 직접 설정했으며,\n",
    "    이는 각 데이터셋 별로 다르게 직접 대입해가며 설정함'''\n",
    "    dt = DecisionTreeClassifier(min_impurity_decrease = 0.05, random_state = 24)\n",
    "    params = {'min_impurity_decrease' : [0.1]}\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state = 24), params)\n",
    "    svc = SVC(C = 0.1, random_state = 24)\n",
    "    lg = LogisticRegression(C = 0.01, max_iter = max_iter,random_state = 24)\n",
    "    sgd = SGDClassifier(alpha = 1, max_iter = max_iter, tol = None, random_state = 24)\n",
    "    \n",
    "    models = [dt, rf, svc, lg, sgd]\n",
    "    \n",
    "    print(f'{name}\\'s performance summary', end = '\\n\\n\\n\\n')\n",
    "    '''훈련 데이터의 정확도와 테스트 데이터의 정확도를 확인할 수 있고,\n",
    "    precision과 recall을 모델에 대한 성능 지표로 활용'''\n",
    "    for m in models:\n",
    "        m.fit(train_scaled, train_target)\n",
    "        test_pred = m.predict(test_scaled)\n",
    "        \n",
    "        train_accuracy = m.score(train_scaled, train_target)\n",
    "        test_accuracy = m.score(test_scaled, test_target)\n",
    "        \n",
    "        precision = precision_score(test_target, test_pred, average = 'weighted')\n",
    "        recall = recall_score(test_target, test_pred, average = 'weighted')\n",
    "\n",
    "        print(f'{m}')\n",
    "        print('----------------------------------------------------------------')\n",
    "        print(f'Precision: {precision:.3f}, Recall: {recall:.3f}, Accuracy_train : {train_accuracy:.3f}, Accuracy_test :  {test_accuracy:.3f}')\n",
    "        print('----------------------------------------------------------------', end = '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 628,
   "id": "f36c74d8",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine_dataset's performance summary\n",
      "\n",
      "\n",
      "\n",
      "DecisionTreeClassifier(min_impurity_decrease=0.05, random_state=24)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.934, Recall: 0.933, Accuracy_train : 0.970, Accuracy_test :  0.933\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "GridSearchCV(estimator=RandomForestClassifier(random_state=24),\n",
      "             param_grid={'min_impurity_decrease': [0.1]})\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.980, Recall: 0.978, Accuracy_train : 0.992, Accuracy_test :  0.978\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "SVC(C=0.1, random_state=24)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.958, Recall: 0.956, Accuracy_train : 0.985, Accuracy_test :  0.956\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "LogisticRegression(C=0.01, max_iter=10000, random_state=24)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.959, Recall: 0.956, Accuracy_train : 0.992, Accuracy_test :  0.956\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "SGDClassifier(alpha=1, max_iter=10000, random_state=24, tol=None)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.959, Recall: 0.956, Accuracy_train : 0.992, Accuracy_test :  0.956\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "five_classification_model(wine)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cd53d74",
   "metadata": {},
   "source": [
    "#### 유방암 데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 672,
   "id": "2bb1c1a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_classification_model(data, max_iter = 10000):\n",
    "    \n",
    "    # EDA\n",
    "    #toydata_eda(data)\n",
    "    \n",
    "    '''토이 데이터에서 feature와 그에 대한 클래스를 저장하고, 데이터 이름을 저장'''\n",
    "    feature_data = data.data\n",
    "    label_data = data.target\n",
    "    name = wine.DESCR.split('\\n')[0][4:-1]\n",
    "        \n",
    "    # 훈련 데이터, 테스트 데이터 분리\n",
    "    '''훈련 데이터와 테스트 데이터로 나눌 때 비율은 초기값을 사용'''\n",
    "    train_input, test_input, train_target, test_target = train_test_split(feature_data, label_data, random_state = 24)\n",
    "    \n",
    "    # 정규화\n",
    "    '''feature 별로 숫자의 척도가 달라, 스케일링, 정규화'''\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "    \n",
    "    # 모델 셋팅\n",
    "    '''과대적합, 과소적합이 일어나지 않도록 규제에 대한 파라미터를 직접 설정했으며,\n",
    "    이는 각 데이터셋 별로 다르게 직접 대입해가며 설정함'''\n",
    "    dt = DecisionTreeClassifier(min_impurity_decrease = 0.01, random_state = 24)\n",
    "    params = {'min_impurity_decrease' : [0.01]}\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state = 24), params)\n",
    "    svc = SVC(C = 0.5, random_state = 24)\n",
    "    lg = LogisticRegression(C = 0.1, max_iter = max_iter,random_state = 24)\n",
    "    sgd = SGDClassifier(loss = 'log', alpha = 0.05, max_iter = max_iter, tol = None, random_state = 24)\n",
    "    \n",
    "    models = [dt, rf, svc, lg, sgd]\n",
    "    \n",
    "    print(f'{name}\\'s performance summary', end = '\\n\\n\\n\\n')\n",
    "    '''훈련 데이터의 정확도와 테스트 데이터의 정확도를 확인할 수 있고,\n",
    "    precision과 recall을 모델에 대한 성능 지표로 활용'''\n",
    "    for m in models:\n",
    "        m.fit(train_scaled, train_target)\n",
    "        test_pred = m.predict(test_scaled)\n",
    "        \n",
    "        train_accuracy = m.score(train_scaled, train_target)\n",
    "        test_accuracy = m.score(test_scaled, test_target)\n",
    "        \n",
    "        precision = precision_score(test_target, test_pred, average = 'weighted')\n",
    "        recall = recall_score(test_target, test_pred, average = 'weighted')\n",
    "    \n",
    "        print(f'{m}')\n",
    "        print('----------------------------------------------------------------')\n",
    "        print(f'Precision: {precision:.3f}, Recall: {recall:.3f}, Accuracy_train : {train_accuracy:.3f}, Accuracy_test :  {test_accuracy:.3f}')\n",
    "        print('----------------------------------------------------------------', end = '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 673,
   "id": "9946daeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine_dataset's performance summary\n",
      "\n",
      "\n",
      "\n",
      "DecisionTreeClassifier(min_impurity_decrease=0.01, random_state=24)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.944, Recall: 0.944, Accuracy_train : 0.974, Accuracy_test :  0.944\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "GridSearchCV(estimator=RandomForestClassifier(random_state=24),\n",
      "             param_grid={'min_impurity_decrease': [0.01]})\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.958, Recall: 0.958, Accuracy_train : 0.979, Accuracy_test :  0.958\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "SVC(C=0.5, random_state=24)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.972, Recall: 0.972, Accuracy_train : 0.984, Accuracy_test :  0.972\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "LogisticRegression(C=0.1, max_iter=10000, random_state=24)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.972, Recall: 0.972, Accuracy_train : 0.981, Accuracy_test :  0.972\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "SGDClassifier(alpha=0.05, loss='log', max_iter=10000, random_state=24, tol=None)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.980, Recall: 0.979, Accuracy_train : 0.974, Accuracy_test :  0.979\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "five_classification_model(bcan)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef225d83",
   "metadata": {},
   "source": [
    "#### 손글씨데이터"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 674,
   "id": "ed41f009",
   "metadata": {},
   "outputs": [],
   "source": [
    "def five_classification_model(data, max_iter = 10000):\n",
    "    \n",
    "    # EDA\n",
    "    #toydata_eda(data)\n",
    "    \n",
    "    '''토이 데이터에서 feature와 그에 대한 클래스를 저장하고, 데이터 이름을 저장'''\n",
    "    feature_data = data.data\n",
    "    label_data = data.target\n",
    "    name = wine.DESCR.split('\\n')[0][4:-1]\n",
    "        \n",
    "    # 훈련 데이터, 테스트 데이터 분리\n",
    "    '''훈련 데이터와 테스트 데이터로 나눌 때 비율은 초기값을 사용'''\n",
    "    train_input, test_input, train_target, test_target = train_test_split(feature_data, label_data, random_state = 24)\n",
    "    \n",
    "    # 정규화\n",
    "    '''feature 별로 숫자의 척도가 달라, 스케일링, 정규화'''\n",
    "    ss = StandardScaler()\n",
    "    ss.fit(train_input)\n",
    "    train_scaled = ss.transform(train_input)\n",
    "    test_scaled = ss.transform(test_input)\n",
    "    \n",
    "    # 모델 셋팅\n",
    "    '''과대적합, 과소적합이 일어나지 않도록 규제에 대한 파라미터를 직접 설정했으며,\n",
    "    이는 각 데이터셋 별로 다르게 직접 대입해가며 설정함'''\n",
    "    dt = DecisionTreeClassifier(min_impurity_decrease = 0.001, random_state = 24)\n",
    "    params = {'min_impurity_decrease' : [0.01]}\n",
    "    rf = GridSearchCV(RandomForestClassifier(random_state = 24), params)\n",
    "    svc = SVC(C = 0.5, random_state = 24)\n",
    "    lg = LogisticRegression(C = 0.1, max_iter = max_iter,random_state = 24)\n",
    "    sgd = SGDClassifier(loss = 'log',alpha = 0.05, max_iter = max_iter, tol = None, random_state = 24)\n",
    "    \n",
    "    models = [dt, rf, svc, lg, sgd]\n",
    "    \n",
    "    print(f'{name}\\'s performance summary', end = '\\n\\n\\n\\n')\n",
    "    '''훈련 데이터의 정확도와 테스트 데이터의 정확도를 확인할 수 있고,\n",
    "    precision과 recall을 모델에 대한 성능 지표로 활용'''\n",
    "    for m in models:\n",
    "        m.fit(train_scaled, train_target)\n",
    "        test_pred = m.predict(test_scaled)\n",
    "        \n",
    "        train_accuracy = m.score(train_scaled, train_target)\n",
    "        test_accuracy = m.score(test_scaled, test_target)\n",
    "        \n",
    "        precision = precision_score(test_target, test_pred, average = 'weighted')\n",
    "        recall = recall_score(test_target, test_pred, average = 'weighted')\n",
    "    \n",
    "        print(f'{m}')\n",
    "        print('----------------------------------------------------------------')\n",
    "        print(f'Precision: {precision:.3f}, Recall: {recall:.3f}, Accuracy_train : {train_accuracy:.3f}, Accuracy_test :  {test_accuracy:.3f}')\n",
    "        print('----------------------------------------------------------------', end = '\\n\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 675,
   "id": "0ee1df1d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wine_dataset's performance summary\n",
      "\n",
      "\n",
      "\n",
      "DecisionTreeClassifier(min_impurity_decrease=0.001, random_state=24)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.875, Recall: 0.862, Accuracy_train : 0.980, Accuracy_test :  0.862\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "GridSearchCV(estimator=RandomForestClassifier(random_state=24),\n",
      "             param_grid={'min_impurity_decrease': [0.01]})\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.932, Recall: 0.929, Accuracy_train : 0.950, Accuracy_test :  0.929\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "SVC(C=0.5, random_state=24)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.979, Recall: 0.978, Accuracy_train : 0.991, Accuracy_test :  0.978\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "LogisticRegression(C=0.1, max_iter=10000, random_state=24)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.961, Recall: 0.960, Accuracy_train : 0.989, Accuracy_test :  0.960\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n",
      "SGDClassifier(alpha=0.05, loss='log', max_iter=10000, random_state=24, tol=None)\n",
      "----------------------------------------------------------------\n",
      "Precision: 0.947, Recall: 0.944, Accuracy_train : 0.956, Accuracy_test :  0.944\n",
      "----------------------------------------------------------------\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "five_classification_model(digits)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15f3ff26",
   "metadata": {},
   "source": [
    "# 회고"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dee40b4d",
   "metadata": {},
   "source": [
    "scikit-learn 라이브러리에서 제공하는 toy dataset을 가지고, 다섯가지 분류 알고리즘을 활용하여, 훈련시킨 모델로부터 테스트 데이터를 얼만큼 잘 예측했는지 확인해보았다.\n",
    "\n",
    "데이터는 손글씨, 와인, 유방암을 데이터를 사용했으며, toydata_eda 함수를 만들어서 데이터의 구조를 살펴보았다.\n",
    "\n",
    "Datasets summary\n",
    "1. 손글씨 데이터는 1797개의 샘플에 대하여 64개의 feature로부터 숫자 0부터 9까지 10개의 다중 클래스\n",
    "2. 와인 데이터는 178개의 샘플에 대하여 13개의 feature로부터 와인 종류 3개라는 다중 클래스\n",
    "3. 유방암 데이터는 569개의 샘플에 대하여 30개의 feature로부터 악성과 양성의 binary 클래스\n",
    "\n",
    "세 가지 데이터셋트의 feature들은 모두 연속형 데이터이다. 그리고, 적게는 13개, 많게는 64개의 feature을 가지고 있으며, 척도가 달라 스케일링이 필요하기 때문에 scikit-learn에서 제공하는 StandardScaler 메소드를 통해서 정규화를 진행하였다.\n",
    "\n",
    "다섯가지 분류모델은 DecisionTree, RandomForest, SVM, LogisticRegression, SGDClassifier를 사용했다.\n",
    "\n",
    "세 가지의 다른 데이터에 대하여 다섯가지 분류 모델을 적용해서 1)모델 성능 평가 전에, 데이터 구조와 분류 모델의 고리즘을 고려했을 때 어떤 분류 모델이 적합할지 예상해보고 2)결과적으로 어떤 데이터에 어느 분류 모델을 적용했을때의 성능이 좋은지 또는 안좋은지에 대해 살펴보았다.\n",
    "\n",
    "\n",
    "먼저 손글씨 데이터는 8x8 픽셀에 담긴 0부터 9까지의 숫자를 진하기 강도에 따라 0부터16이라는 숫자로 나타냈다.\n",
    "각 픽셀에 담긴 진하기 정도에 따른 숫자 모양을 정답으로 알려주고, 새로운 8x8픽셀에 담긴 숫자에 대한 진하기 강도 정보가 주어지면, 해당 숫자가 0~9에서 어떤 숫자인지를 분류하는 문제이다. 이처럼 손글씨에 데이터는 샘플도 많고 차원도 많기 때문에, 다량의 데이터를 점진적으로 학습하는 SGDClassifier가 성능이 좋을 것으로 예상했고,\n",
    "\n",
    "\n",
    "와인 데이터는 다중 클래스에 대한 분류 문제에 대해서는 LogisticRegression 알고리즘만 정확히 학습한 상황이므로, LogisticRegression가 좋은 성능을 가질 것이라고 예상을 했다. 그리고 악성, 양성 종양인지 binary class 모델도 LogisticRegression이 좋은 성능을 발휘할 것으로 예상했다. 다중 클래스가 아니더라도 binary 클래스가 주어지면 이진분류로 진행하기 때문에, 가장 최적화되서? 좋은 성능을 보여줄 것으로 예상했다.\n",
    "\n",
    "위의 five_classification_model함수에서는 모든 과정이 함축적으로 담겨있지만, 원래는 데이터 별로 모델에 규제 파라미터를 입력해가며,,,(거의 하이퍼파라미터 수준) 과소적합과 과대적합을 회피하고자 하였다. 훈련 데이터 세트로 학습한 모델로 각각의 훈련 데이터 세트와 테스트 데이터 세트를 score메서드로 평가해보면 훈련 세트의 점수와 테스트 세트의 점수를 알 수 있다.\n",
    "\n",
    "이 때, 훈련 세트의 점수와 테스트 세트의 점수가 둘 다 모두 낮거나, 또는, 테스트 세트의 점수가 훈련 세트의 점수보다 높을 때 '과소적합'이라고 판단하고, 훈련 세트의 점수가 테스트 세트의 점수보다 월등히 높거나, 100% 정확하다고 나온다면 '과대적합'으로 판단했다. 그리하여 훈련 세트 점수와 테스트 세트의 점수가 둘다 90%이상의 예측 점수를 보이면서, 둘의 차이가 크지 않고, 훈련 세트의 점수가 조금 더 크게 나올 때를 이상적인 모델로 판단했으며, 이때가 나올 때까지 규제 파라미터를 manual로 입력해가면서 최적은 파라미터를 찾은 것이, 위의 함수에 내포된 파라미터다.(각 데이터 별로 모델의 규제 파라미터가 다름). \n",
    "\n",
    "그래서 아쉬운 점은 규제 파라미터를 찾는 과정을 어느 정도 범위의 숫자를 automatically하게 for문을 돌려가면서 최적의 파라미터를 찾아서 적용하는 코드를 만들면 어떨까 생각했다. 그럼 혹시 더 무거워지지는 않을까도 생각해보았지만, 이렇게 만들어 놓으면 나중에 데이터만 집어넣고 최적은 파라미터를 프로그래밍으로 찾을 수 있으니까 이번 Ex1과제 끝나고 조금씩 코딩해볼 계획이다.\n",
    "\n",
    "각 데이터에 대해 five_classification_model함수를 사용해서 최종적으로 precision과 recall값을 출력하도록 만들었다. 각 데이터 별로 둘 중에 어느 지표를 사용할지가 달랐다. 유방암의 악성 또는 양성을 판정해주는 분류 모델의 경우, 악성 종양에 대해 양성으로 판단하게되면 환자의 예후가 좋지 않기 때문에, 이같은 문제에서는 결과로 주어진 값이 얼마나 신뢰할수 있는지, 얼마나 틀리지 않는 것이 중요하므로 precision의 척도를 선택했으며, 나머지는 조금은 부정확하더라도 최대한 많이 맞추는 것이 성능이 좋다고 판단할 수 있기 때문에 recall을 성능 지표로 활용하였다.\n",
    "\n",
    "Recall을 성능 평가의 지표로 활용한 와인과 손글씨 데이터에 대한 점수는 0.978, 0.978가 도출되었다. precision을 성능 평가의 지표로 활용한 유방암 데이터는 0.980이 도출되었다.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b1f904c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
